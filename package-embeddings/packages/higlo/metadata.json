{
  "package": "higlo",
  "embedding_model": "Qwen/Qwen3-Embedding-8B",
  "embedding_dimension": 4096,
  "total_modules": 9,
  "creation_timestamp": "2025-08-15T07:41:19.887777",
  "modules": [
    {
      "module_path": "Higlo.Misc",
      "library": "higlo",
      "description": "Splits strings into parts based on a list of separator characters, optionally including empty segments. Tests whether one string is a prefix of another. Removes leading and trailing whitespace from a string. Useful for parsing and normalizing text input.",
      "description_length": 254,
      "index": 0,
      "embedding_norm": 1.0
    },
    {
      "module_path": "Higlo.Printers",
      "library": "higlo",
      "description": "This module provides functions to convert lexical tokens into XML or rewrite trees using customizable styling classes. It works with token lists and string-based language identifiers, supporting syntax highlighting for different programming languages. Key operations include token-to-XML mapping, full code parsing and transformation, and dynamic registration of custom printers for specific languages.",
      "description_length": 402,
      "index": 1,
      "embedding_norm": 1.0
    },
    {
      "module_path": "Higlo.Lang",
      "library": "higlo",
      "description": "This module defines token types and operations for syntax highlighting, including lexers that process source code into categorized tokens like keywords, strings, and comments. It works with strings and lexing buffers to parse code in specific languages, merging consecutive text tokens for efficiency. Use cases include implementing syntax highlighters for code editors or generating tokenized output for analysis tools.",
      "description_length": 420,
      "index": 2,
      "embedding_norm": 0.9999999403953552
    },
    {
      "module_path": "Higlo.Xml",
      "library": "higlo",
      "description": "This component provides low-level XML parsing capabilities through lexing and tokenization operations, utilizing `Sedlexing.lexbuf` for input processing. It focuses on converting XML syntax into structured token sequences, handling tasks like tag recognition, lexeme extraction, and state-based character classification via internally generated partition tables. Designed for XML stream analysis, it serves use cases requiring precise syntactic breakdowns of XML content into processable elements.",
      "description_length": 497,
      "index": 3,
      "embedding_norm": 1.0
    },
    {
      "module_path": "Higlo.Commonmark",
      "library": "higlo",
      "description": "Implements lexical analysis operations for CommonMark parsing, including UTF-8 character classification, state transition handling, and lexeme extraction using Sedlex-generated tables. Operates on `Sedlexing.lexbuf` buffers and integer-coded character streams to tokenize markdown elements like code blocks, inline syntax, and structural punctuation.",
      "description_length": 350,
      "index": 4,
      "embedding_norm": 1.0
    },
    {
      "module_path": "Higlo.Json",
      "library": "higlo",
      "description": "This module provides Unicode-aware lexical analysis and tokenization operations for parsing JSON structures, focusing on efficient character classification and lexeme extraction. It works with internal lookup tables and partition functions generated by SEDLEX to handle UTF-8 encoded input, enabling precise recognition of JSON tokens like object keys and values. The implementation is optimized for scenarios requiring robust handling of international character sets and complex Unicode data streams.",
      "description_length": 501,
      "index": 5,
      "embedding_norm": 1.0
    },
    {
      "module_path": "Higlo.Ocaml",
      "library": "higlo",
      "description": "This module implements low-level lexical analysis operations for Unicode-aware token recognition, focusing on character classification, state transitions, and lexeme boundary detection. It operates on precomputed lookup tables (strings), integer-encoded character codes, and `Sedlexing.lexbuf` buffers to enable efficient pattern matching and automaton-based parsing. These components are specifically used to tokenize OCaml source code, handle encoding ranges, and extract structured tokens during compilation or syntax processing tasks.",
      "description_length": 538,
      "index": 6,
      "embedding_norm": 1.0
    },
    {
      "module_path": "Higlo.Dot",
      "library": "higlo",
      "description": "This module provides lexical analysis operations for tokenizing input streams using SEDLEX-generated finite automata. It works with lexing buffers, token lists, and integer-based state transition tables to map character sequences to lexical partitions. The implementation handles character classification, lexeme extraction, and state transitions for parsing Higlo's grammar, particularly supporting token recognition in formal language processing tasks.",
      "description_length": 454,
      "index": 7,
      "embedding_norm": 1.0
    },
    {
      "module_path": "Higlo",
      "library": "higlo",
      "description": "This module implements lexical analysis operations for multiple structured formats, including JSON, XML, and CommonMark, using SEDLEX-generated tokenization engines. It works with lexing buffers, token lists, and UTF-8 character streams to extract structured tokens for parsing and syntax processing tasks. Concrete use cases include syntax highlighting in code editors, formal language parsing, and Unicode-aware data stream analysis.",
      "description_length": 435,
      "index": 8,
      "embedding_norm": 1.0
    }
  ],
  "filtering": {
    "total_modules_in_package": 9,
    "meaningful_modules": 9,
    "filtered_empty_modules": 0,
    "retention_rate": 1.0
  },
  "statistics": {
    "max_description_length": 538,
    "min_description_length": 254,
    "avg_description_length": 427.8888888888889,
    "embedding_file_size_mb": 0.13088321685791016
  }
}