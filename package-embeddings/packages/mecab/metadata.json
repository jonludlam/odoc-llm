{
  "package": "mecab",
  "embedding_model": "Qwen/Qwen3-Embedding-8B",
  "embedding_dimension": 4096,
  "total_modules": 7,
  "creation_timestamp": "2025-08-14T23:12:28.996208",
  "modules": [
    {
      "module_path": "Mecab.Unicode.Make",
      "library": "mecab",
      "description": "This module provides functions to construct and manipulate Unicode character sequences (`S.t`) using transformations like mapping, folding, and filtering, alongside normalization operations such as case conversion, whitespace standardization, and encoding adjustments (e.g., full-width to ASCII). It specializes in preprocessing text for linguistic analysis, particularly Japanese, by resolving inconsistencies in character representations, such as Neologd-style normalization or half-width katakana conversion. Applications include preparing input for morphological analysis by harmonizing diverse encodings and eliminating formatting irregularities.",
      "description_length": 651,
      "index": 0,
      "embedding_norm": 1.0
    },
    {
      "module_path": "Mecab.Unicode.Char",
      "library": "mecab",
      "description": "This module provides character classification functions to determine Unicode script membership (e.g., ASCII, Cyrillic, Arabic) and Japanese-specific character sets (hiragana, katakana, kanji), including width variants. It operates on Unicode characters represented as `CamomileLibraryDefault.Camomile.UChar.uchar`, supporting tasks like text normalization and tokenization in Japanese language processing. Specific applications include identifying whitespace, punctuation, and script boundaries for morphological analysis.",
      "description_length": 522,
      "index": 1,
      "embedding_norm": 1.0
    },
    {
      "module_path": "Mecab.Unicode.UTF8",
      "library": "mecab",
      "description": "This module offers utilities for transforming and normalizing UTF-8 strings through operations like character mapping, filtering, case conversion, and predicate-based trimming, alongside advanced transformations such as numeric form normalization, kana expansion, and spacing adjustment. It operates on UTF-8 encoded strings and lists of Unicode characters, enabling preprocessing tasks like standardizing multilingual text, preparing input for morphological analysis, and handling Japanese-specific orthographic variations. Specific applications include converting full-width ASCII to narrow forms, normalizing neologisms in Japanese text, and ensuring consistent spacing for linguistic analysis.",
      "description_length": 697,
      "index": 2,
      "embedding_norm": 1.0
    },
    {
      "module_path": "Mecab.Unicode",
      "library": "mecab",
      "description": "This module provides text normalization operations for Unicode characters and UTF-8 strings, including script classification, case conversion, whitespace standardization, and encoding adjustments. It works with Unicode characters (`uchar`) and string types, focusing on Japanese-specific transformations like full-width to ASCII conversion, kana normalization, and handling of hiragana, katakana, and kanji. Concrete use cases include preprocessing input for morphological analysis, resolving inconsistent encodings in Japanese text, and standardizing spacing and punctuation for linguistic processing.",
      "description_length": 602,
      "index": 3,
      "embedding_norm": 1.0
    },
    {
      "module_path": "Mecab.Node",
      "library": "mecab",
      "description": "This module represents nodes in a parsed sentence, providing access to linguistic features like part-of-speech, word cost, and marginal probabilities when enabled. It works with node data structures containing surface forms, attributes, and parsing metadata. Concrete use cases include extracting morphological features for NLP tasks and analyzing parsing confidence using `prob` or `cost` values.",
      "description_length": 397,
      "index": 4,
      "embedding_norm": 1.0
    },
    {
      "module_path": "Mecab.Tagger",
      "library": "mecab",
      "description": "This module provides operations to configure morphological analysis engines, perform sparse text analysis, and retrieve dictionary metadata using customizable lattice processing modes. It works with strings, node lists, and dictionary structures while supporting incremental analysis and n-best parsing for handling ambiguous Japanese text. Specific use cases include fine-tuning analysis behavior through configuration flags and generating multiple morphological interpretations for downstream natural language processing tasks.",
      "description_length": 529,
      "index": 5,
      "embedding_norm": 1.0
    },
    {
      "module_path": "Mecab",
      "library": "mecab",
      "description": "This module integrates MeCab for Japanese natural language processing, offering direct access to morphological analysis, node-level linguistic features, and Unicode text normalization. It handles strings, node sequences, and dictionary structures, enabling tasks like tokenization, part-of-speech tagging, and probabilistic parsing. Specific applications include preprocessing Japanese text for analysis, extracting linguistic attributes with confidence scores, and normalizing encodings or kana variants.",
      "description_length": 505,
      "index": 6,
      "embedding_norm": 1.0
    }
  ],
  "filtering": {
    "total_modules_in_package": 7,
    "meaningful_modules": 7,
    "filtered_empty_modules": 0,
    "retention_rate": 1.0
  },
  "statistics": {
    "max_description_length": 697,
    "min_description_length": 397,
    "avg_description_length": 557.5714285714286,
    "embedding_file_size_mb": 0.10183429718017578
  }
}