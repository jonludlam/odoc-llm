{
  "package": "lib_parsing",
  "embedding_model": "BAAI/bge-base-en-v1.5",
  "embedding_dimension": 1024,
  "total_modules": 11,
  "creation_timestamp": "2025-06-18T16:31:27.476513",
  "modules": [
    {
      "module_path": "lib_parsing",
      "description": "Processes and validates structured text input, extracting key-value pairs and nested data elements. Operates on strings, lists, and custom record types representing parsed content. Used to transform configuration files and log entries into accessible data models for further processing.",
      "description_length": 286,
      "index": 0,
      "embedding_norm": 1.0
    },
    {
      "module_path": "Lib_ast_fuzzy",
      "description": "Constructs and manipulates fuzzy parse trees from token lists using custom hooks, and converts between token sequences and tree structures. Processes token kinds and positions, enabling position-aware transformations of abstract syntax trees. Supports visitor patterns for tree traversal and modification.",
      "description_length": 305,
      "index": 1,
      "embedding_norm": 1.0
    },
    {
      "module_path": "Parsing_result",
      "description": "type ('ast, 'toks) t = { ast: 'ast; tokens: 'toks; errors: string list } Provides access to parsed abstract syntax trees, remaining token streams, and error logs from parsing processes. Works with custom AST types and token sequences generated by lexers. Used to validate parser outputs and debug syntax issues in language implementations.",
      "description_length": 339,
      "index": 2,
      "embedding_norm": 1.0
    },
    {
      "module_path": "Parsing_helpers",
      "description": "Provides functions to manage token states, adjust positions in lexing buffers, and handle token location adjustments for parsing. Works with token lists, lexing buffers, and position tracking structures. Used to process and correct token positions after file transformations or during error reporting.",
      "description_length": 301,
      "index": 3,
      "embedding_norm": 1.0
    },
    {
      "module_path": "Parsing_stat",
      "description": "Provides functions to generate and analyze parsing statistics from filenames, including generating default, bad, and correct stats. Works with custom types `t` and `ast_stat` to track parsing outcomes and recurring issues. Includes concrete use cases like printing detailed parsing summaries, aggregating results, and identifying regression patterns in code.",
      "description_length": 358,
      "index": 4,
      "embedding_norm": 1.0
    },
    {
      "module_path": "Parse_info",
      "description": "This module offers operations for manipulating token metadata, including pretty-printing, equality checks, and creating/modifying token information structures, while handling token locations, filenames, and string data. It supports tasks like tracking source code positions, managing bracket hierarchies, and extracting metadata, with utilities for abstracting token origins and comparing positional data. Specific use cases include parsing, code analysis, and transformation tools requiring precise token tracking.",
      "description_length": 515,
      "index": 5,
      "embedding_norm": 0.9999999403953552
    },
    {
      "module_path": "Loc",
      "description": "Provides operations to create and manipulate location ranges using token positions, including unions, extensions, and range adjustments. Works with tuples of token objects representing start and end positions. Used to track source code ranges for error reporting and parsing context tracking.",
      "description_length": 292,
      "index": 6,
      "embedding_norm": 1.0
    },
    {
      "module_path": "Skip_code",
      "description": "Loads a skip list from a file, filters filenames against it based on a root directory, reorders files to move skipped ones to the end, and generates an error file based on the skip list. Works with filenames, directory names, and a custom skip list type. Used to manage file processing pipelines by excluding specified files and handling errors explicitly.",
      "description_length": 356,
      "index": 7,
      "embedding_norm": 1.0
    },
    {
      "module_path": "Flag_parsing",
      "description": "Provides flags to control verbosity and behavior during lexing and parsing, including error handling and debugging options. Works with boolean reference types and command-line argument specifications. Used to enable detailed logging, error recovery, and specialized parsing modes like sgrep.",
      "description_length": 291,
      "index": 8,
      "embedding_norm": 0.9999999403953552
    },
    {
      "module_path": "Ast_fuzzy",
      "description": "Checks if a string represents a metavariable by analyzing its format. Operates on strings and a tree structure composed of wrapped elements and lists of trees. Used to parse and validate syntax tree nodes during lexical analysis.",
      "description_length": 229,
      "index": 9,
      "embedding_norm": 1.0
    },
    {
      "module_path": "Meta_parse_info",
      "description": "Provides functions to extract OCaml values from parse information, adjust precision dynamically, and retrieve command-line flag specifications for precision settings. Works with `Parse_info.t` and a mutable `dumper_precision` type that controls output formatting. Used to generate configurable dump outputs and manage precision through command-line arguments.",
      "description_length": 359,
      "index": 10,
      "embedding_norm": 1.0
    }
  ],
  "filtering": {
    "total_modules_in_package": 11,
    "meaningful_modules": 11,
    "filtered_empty_modules": 0,
    "retention_rate": 1.0
  },
  "statistics": {
    "max_description_length": 515,
    "min_description_length": 229,
    "avg_description_length": 330.09090909090907,
    "embedding_file_size_mb": 0.040386199951171875
  }
}