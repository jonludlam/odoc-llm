{
  "package": "lambdapi",
  "embedding_model": "Qwen/Qwen3-Embedding-0.6B",
  "embedding_dimension": 1024,
  "total_modules": 133,
  "creation_timestamp": "2025-07-15T23:33:15.303302",
  "modules": [
    {
      "module_path": "Handle.Compile.PureUpToSign",
      "library": "lambdapi.handle",
      "description": "This module provides `compile` and `compile_file` functions that perform compilation tasks while preserving and restoring the initial console state and library mappings. It operates on file paths and console state data types, returning a signature value as the result of compilation. These functions are used when compiling code units in a way that isolates and resets environmental state after execution.",
      "description_length": 405,
      "index": 0,
      "embedding_norm": 1.0
    },
    {
      "module_path": "Handle.Proof.Goal",
      "library": "lambdapi.handle",
      "description": "This module provides operations to manipulate and inspect proof goals, including retrieving typing contexts, simplifying goals, and converting goals into Bindlib contexts. It works directly with `Handle.Proof.goal` values, which represent individual proof obligations in a tactic system. Concrete use cases include printing goal hypotheses, applying simplification functions to goals, and extracting environments for further term processing.",
      "description_length": 441,
      "index": 1,
      "embedding_norm": 1.0
    },
    {
      "module_path": "Handle.Proof",
      "library": "lambdapi.handle",
      "description": "This module orchestrates proof construction by managing goals and proof states, enabling operations like inspecting typing and unification goals, retrieving constraints, and updating proof states. It works with `Handle.Proof.goal` values to support concrete tasks such as tracking unsolved goals, focusing on specific goals interactively, and extracting metavariables by key. The child module extends this by allowing manipulation of individual goals, including simplification, context extraction, and hypothesis inspection. Together, they enable precise control over proof development, from high-level state management to detailed goal transformation.",
      "description_length": 652,
      "index": 2,
      "embedding_norm": 1.0
    },
    {
      "module_path": "Handle.Inductive",
      "library": "lambdapi.handle",
      "description": "This module generates induction principles for first-order dependent inductive types, handling both single and mutually defined types through individual and combined induction schemes. It operates on symbolic representations of inductive types and their constructors, using environments and term structures to build induction predicates, conclusions, and recursor types. Concrete use cases include automatically deriving induction principles for inductive data types in a proof assistant or type-checking system, where each constructor's structure informs the shape of the induction hypothesis and recursive arguments.",
      "description_length": 618,
      "index": 3,
      "embedding_norm": 1.0
    },
    {
      "module_path": "Handle.Query",
      "library": "lambdapi.handle",
      "description": "This module processes type inference and checking operations for terms within a logical context, refining terms and determining their types under constraint problems. It works with terms, contexts, and constraint problems from the Core module, handling queries related to type correctness and sort validation. Concrete use cases include verifying term typing in a given context, inferring types for untyped terms, and checking that terms inhabit specific sorts like Type or Kind.",
      "description_length": 479,
      "index": 4,
      "embedding_norm": 1.0
    },
    {
      "module_path": "Handle.Compile",
      "library": "lambdapi.handle",
      "description": "This module orchestrates high-level compilation workflows, handling module and file compilation with support for recompilation flags and signature generation. It operates on file paths and module paths, offering functions like `compile` and `compile_file` that execute compilation tasks while managing console state and library mappings. Its core data types include signatures, file paths, and compilation options, enabling use cases such as compiling source files into signatures or recompiling modules with forced updates. The module integrates state management and file-level operations, balancing direct API calls with structured submodules for focused compilation control.",
      "description_length": 677,
      "index": 5,
      "embedding_norm": 0.9999999403953552
    },
    {
      "module_path": "Handle.Rewrite",
      "library": "lambdapi.handle",
      "description": "This module implements the rewrite tactic, providing operations for matching terms against patterns, generating substitutions, and manipulating equality proofs. It works with terms, binders, and equality configurations involving symbols for propositions, types, and equality. Concrete use cases include rewriting goal types using equational lemmas, swapping equality sides, and matching subterms to apply substitutions during proof refinement.",
      "description_length": 443,
      "index": 6,
      "embedding_norm": 1.0
    },
    {
      "module_path": "Handle.Command",
      "library": "lambdapi.handle",
      "description": "This module processes commands in a proof assistant, handling transitions into proof mode and managing proof execution. It works with signature states, proof states, syntax trees for commands and proofs, and compiler functions that load external modules. Concrete operations include extracting proof data from commands, applying tactics, and updating the global state after command execution.",
      "description_length": 392,
      "index": 7,
      "embedding_norm": 0.9999999403953552
    },
    {
      "module_path": "Handle.Tactic",
      "library": "lambdapi.handle",
      "description": "This module implements core proof manipulation operations including tactic application, goal refinement, and axiom handling. It works with proof states, metavariables, inductive data, and term structures to manage logical reasoning steps. Concrete use cases include refining proof goals with terms, applying induction, solving unification constraints, and admitting axioms to handle unsolved goals.",
      "description_length": 398,
      "index": 8,
      "embedding_norm": 1.0
    },
    {
      "module_path": "Handle.Why3_tactic",
      "library": "lambdapi.handle",
      "description": "This module executes Why3 provers to validate proof goals within a specified time limit. It supports setting and retrieving the active prover and timeout value, and directly invokes the prover on a given goal type. It is used to verify logical assertions during proof checking by running external provers like Alt-Ergo or Z3.",
      "description_length": 325,
      "index": 9,
      "embedding_norm": 1.0
    },
    {
      "module_path": "Handle.Fol",
      "library": "lambdapi.handle",
      "description": "This module defines a configuration structure for first-order logic tactics, specifying symbols for logical connectives, quantifiers, and type encodings. It works with terms and symbols from the Core library to represent logical expressions. Use this module to set up and retrieve first-order logic configurations during tactic execution.",
      "description_length": 338,
      "index": 10,
      "embedding_norm": 1.0
    },
    {
      "module_path": "Handle",
      "library": "lambdapi.handle",
      "description": "This module coordinates proof development, type inference, and compilation workflows, integrating goal management, tactic execution, and external prover validation. It supports data types such as goals, proof states, terms, constraints, and compilation units, with operations for goal refinement, induction generation, type checking, and tactic-based term rewriting. You can use it to construct and manipulate proofs interactively, derive induction principles for inductive types, verify term typing in logical contexts, and compile modules with controlled recompilation. Specific tasks include focusing and solving proof goals, rewriting with equational lemmas, running external provers on logical assertions, and configuring first-order logic tactics with custom symbol mappings.",
      "description_length": 781,
      "index": 11,
      "embedding_norm": 0.9999999403953552
    },
    {
      "module_path": "Pure.Tactic",
      "library": "lambdapi.pure",
      "description": "This module defines an abstract representation of a tactic, primarily used for handling proof items in the context of the LSP interface. It provides operations to compare tactics for equality, retrieve their source positions, and format them as strings. Concrete use cases include managing and manipulating proof steps during interactive theorem proving and error reporting in the language server protocol.",
      "description_length": 406,
      "index": 12,
      "embedding_norm": 1.0
    },
    {
      "module_path": "Pure.Command",
      "library": "lambdapi.pure",
      "description": "Represents top-level commands in an LSP interface, providing equality checks, position retrieval, and pretty-printing. Works with command data structures and source positions. Used for managing and displaying individual commands in a language server protocol implementation.",
      "description_length": 274,
      "index": 13,
      "embedding_norm": 1.0
    },
    {
      "module_path": "Pure.ProofTree",
      "library": "lambdapi.pure",
      "description": "Represents and manipulates proof trees with operations to compare trees for equality and to fold over tactics at each node. Works with abstract proof tree structures containing tactics and their nested subgoals. Useful for analyzing proof progress, extracting tactic sequences, or building proof visualizations.",
      "description_length": 311,
      "index": 14,
      "embedding_norm": 1.0
    },
    {
      "module_path": "Pure",
      "library": "lambdapi.pure",
      "description": "This module processes formal proof commands and tactics through an LSP interface, managing proof state transitions while supporting parsing, type checking, and tactic execution. It defines core data types like command lists, proof trees, goals, and symbols, with key operations including `handle_command`, `handle_tactic`, `current_goals`, and `get_symbols`. The module\u2019s submodules provide structured representations of tactics, top-level commands, and proof trees, enabling precise manipulation of proof steps, command metadata, and hierarchical proof structures. Specific use cases include evaluating proof scripts, tracking unresolved goals, comparing tactics and commands for equality, and generating formatted output for LSP clients.",
      "description_length": 739,
      "index": 15,
      "embedding_norm": 1.0000001192092896
    },
    {
      "module_path": "Core.Tree.CP.PSet",
      "library": "lambdapi.core",
      "description": "This module provides persistent set operations for managing collections of integer pairs (`int * int`), supporting efficient union, intersection, difference, and transformations via functions like `map`, `filter`, and `fold`. It works with functional sets represented by `Core.Tree.CP.PSet.t`, enabling safe membership checks, ordered traversal, and conversions to/from sequences. These operations are used in the compilation of rewriting rules to decision trees, where sets of integer pairs represent condition coverage or partitioning during rule analysis.",
      "description_length": 558,
      "index": 16,
      "embedding_norm": 1.0
    },
    {
      "module_path": "Core.Term.Meta",
      "library": "lambdapi.core",
      "description": "This module defines types and operations for working with sets and maps of metavariables, using the internal term representation. It provides comparison functionality to enable ordered collections, specifically using the `Core.Term.meta` type. Concrete use cases include managing metavariable environments in term manipulation and substitution systems.",
      "description_length": 352,
      "index": 17,
      "embedding_norm": 1.0
    },
    {
      "module_path": "Core.Tree_type.TC",
      "library": "lambdapi.core",
      "description": "This module represents atomic pattern constructors for decision trees, with support for symbols, bound variables, and type placeholders. It defines operations for printing and comparing these constructors, enabling precise manipulation and analysis of tree patterns. Concrete use cases include pattern matching compilation and environment building in higher-order term processing.",
      "description_length": 380,
      "index": 18,
      "embedding_norm": 0.9999999403953552
    },
    {
      "module_path": "Core.Tree_type.TCMap",
      "library": "lambdapi.core",
      "description": "This structure implements a polymorphic map using atomic pattern constructors as ordered keys, supporting associative operations like insertion, deletion, and lookup, along with ordered traversal, transformation, and filtering. It organizes key-value pairs where keys are atomic patterns and values are arbitrary types, enabling operations like merging, partitioning, and comparison based on key ordering. It is particularly useful for managing hierarchical data in decision trees, where atomic patterns act as discriminators for organizing and manipulating structured values.",
      "description_length": 576,
      "index": 19,
      "embedding_norm": 1.0
    },
    {
      "module_path": "Core.Tree.CP",
      "library": "lambdapi.core",
      "description": "This module represents and manages constraints for pattern matching compilation, using integer maps and arrays to track variables and store conditions. It coordinates with its child module for persistent set operations on integer pairs, which supports union, intersection, and transformation to analyze condition coverage during rule compilation. Main data types include constraint pools and functional sets of integer pairs, with operations for adding, checking, and transforming conditions. For example, it enables compiling rewriting rules into decision trees by tracking free variables and ensuring correct term matching through set operations on condition partitions.",
      "description_length": 672,
      "index": 20,
      "embedding_norm": 1.0
    },
    {
      "module_path": "Core.Term.VarSet",
      "library": "lambdapi.core",
      "description": "This module provides ordered set operations for managing term variables, including union, intersection, difference, and transformations like mapping or filtering elements. It works with ordered collections of variables, supporting efficient iteration, membership checks, and conversions to and from sequences. These capabilities are used for analyzing variable dependencies or tracking occurrences in term manipulation tasks.",
      "description_length": 425,
      "index": 21,
      "embedding_norm": 1.0
    },
    {
      "module_path": "Core.Term.SymSet",
      "library": "lambdapi.core",
      "description": "This module provides ordered set operations for managing collections of symbolic terms (`sym`), supporting efficient insertion, deletion, union, intersection, and membership checks. It works with ordered sets (`SymSet.t`) that maintain element ordering and enable transformations like mapping, filtering, and partitioning, along with sequence-based iteration and conversion to/from lists or ordered sequences. Designed for scenarios requiring precise symbol tracking in term representations, it optimizes performance through physical equality checks during immutable updates and integrates with binder abstractions for handling variable bindings in formal terms.",
      "description_length": 662,
      "index": 22,
      "embedding_norm": 0.9999999403953552
    },
    {
      "module_path": "Core.Term.Sym",
      "library": "lambdapi.core",
      "description": "This module implements sets and maps keyed by symbols, using the internal symbol type from Core.Term. It provides standard collection operations like adding, removing, and comparing elements, specifically tailored for symbol-based keys. Useful for managing symbol tables or tracking unique identifiers in term manipulations.",
      "description_length": 324,
      "index": 23,
      "embedding_norm": 0.9999999403953552
    },
    {
      "module_path": "Core.Term.Var",
      "library": "lambdapi.core",
      "description": "This module implements sets and maps for term variables, using the `Core.Term.tvar` type as keys. It provides standard set and map operations such as membership testing, insertion, and lookup, along with a total ordering function for comparing term variables. These structures are used to manage variable bindings and track variable usage in term manipulations.",
      "description_length": 361,
      "index": 24,
      "embedding_norm": 1.0
    },
    {
      "module_path": "Core.Term.MetaSet",
      "library": "lambdapi.core",
      "description": "This module provides operations for manipulating ordered sets of term metavariables (Core.Term.Meta.t) with a focus on ordered iteration, set algebra, and sequence-based construction. It supports standard set operations (union, intersection, filtering) alongside ordered decomposition, element search using total ordering, and bidirectional conversion between sets and ordered sequences. Typical use cases include tracking metavariable dependencies, ordered term traversal, and constructing sets from sequential data while preserving ordering guarantees.",
      "description_length": 554,
      "index": 25,
      "embedding_norm": 1.0
    },
    {
      "module_path": "Core.Tree.CM",
      "library": "lambdapi.core",
      "description": "This module enables compiling pattern matching into decision trees by constructing and transforming clause matrices, selecting optimal columns for specialization, and evaluating conditions to determine term rewriting. It handles data structures including terms, clauses with substitutions and constraints, and matrices that pair patterns with right-hand sides, supporting operations like constructor-based specialization, exhaustiveness checks, and filtering through wildcards or binders. It is used in functional language compilers to optimize pattern matching by systematically analyzing and resolving complex patterns during term reduction.",
      "description_length": 643,
      "index": 26,
      "embedding_norm": 0.9999999403953552
    },
    {
      "module_path": "Core.Term.Raw",
      "library": "lambdapi.core",
      "description": "This module provides a low-level printer for internal term representations, specifically using the `Core.Term.term` type. It leverages the `Lplib.Base.pp` pretty-printing facility to format terms for debugging purposes. Direct use cases include inspecting term structures during development or logging terms in error messages.",
      "description_length": 326,
      "index": 27,
      "embedding_norm": 1.0
    },
    {
      "module_path": "Core.Term.SymMap",
      "library": "lambdapi.core",
      "description": "This module implements symbol-keyed maps with efficient operations for inserting, modifying, and querying associations between symbolic terms (`Core.Term.sym`) and arbitrary values. It emphasizes ordered traversal, bulk updates via sequences, and transformations like filtering or partitioning, while supporting extremal key access and conversion to ordered structures like lists or sequences. Designed for managing term symbols in compiler internals, it enables use cases like variable binding tracking, hierarchical term manipulation, and ordered symbol processing in formal systems.",
      "description_length": 585,
      "index": 28,
      "embedding_norm": 1.0
    },
    {
      "module_path": "Core.Term.VarMap",
      "library": "lambdapi.core",
      "description": "This module provides a collection of ordered map operations for managing key-value associations where keys are term variables (`Core.Term.tvar`) from the Bindlib-based term representation. It supports standard map manipulations (insertion, deletion, union, filtering) alongside ordered traversal, folding, and conversion to/from sequences or lists, with specialized utilities for key-range iteration and list-based accumulation. Such functionality is particularly useful for implementing substitution environments, variable binding tracking, or ordered term variable metadata management in compiler or proof assistant workflows.",
      "description_length": 628,
      "index": 29,
      "embedding_norm": 1.0
    },
    {
      "module_path": "Core.Term.MetaMap",
      "library": "lambdapi.core",
      "description": "This module implements a map structure for associating `Meta.t` keys with arbitrary data, offering standard operations like insertion, removal, and lookup, alongside ordered traversal and sequence-based construction. It optimizes for physical equality of keys and supports efficient range queries, ordered processing, and bulk transformations, making it suitable for managing metadata in term representations where key ordering and iterative updates are critical.",
      "description_length": 463,
      "index": 30,
      "embedding_norm": 1.0
    },
    {
      "module_path": "Core.LibTerm",
      "library": "lambdapi.core",
      "description": "This module provides operations for inspecting and manipulating terms, including checking term kinds, extracting variables, removing implicit arguments, and traversing term structures. It works with term data types, binders, contexts, and variable mappings. Concrete use cases include analyzing term structure for type checking, managing bound variables during substitution, and preparing terms for further processing by stripping or transforming specific components.",
      "description_length": 467,
      "index": 31,
      "embedding_norm": 1.0
    },
    {
      "module_path": "Core.Sig_state",
      "library": "lambdapi.core",
      "description": "This module manages the state of a signature during term processing, providing operations to manipulate scope and visibility of symbols, notations, and builtins. It works with signature states that track symbols, paths, and open modules, enabling structured symbol resolution and scoped additions. Concrete use cases include resolving qualified identifiers during term printing and maintaining context when extending or opening signatures.",
      "description_length": 439,
      "index": 32,
      "embedding_norm": 1.0
    },
    {
      "module_path": "Core.Tree_type",
      "library": "lambdapi.core",
      "description": "This module provides data structures and operations for decision trees used in term rewriting systems, centered around types like `tree_cond` for conditions on term convertibility and free variables, and `rhs_substit` for tracking substitutions. It supports operations such as tree construction with pattern-based branching and computing tree storage capacity, enabling precise control over decision paths and rewrite rule application. The first child module introduces atomic pattern constructors\u2014symbols, bound variables, and type placeholders\u2014with comparison and printing operations that support pattern matching compilation and environment building. The second extends this with a polymorphic map keyed on atomic patterns, enabling associative and ordered manipulation of hierarchical data, such as rule sets or decision branches, based on pattern keys.",
      "description_length": 857,
      "index": 33,
      "embedding_norm": 0.9999999403953552
    },
    {
      "module_path": "Core.Inverse",
      "library": "lambdapi.core",
      "description": "This module computes the inverse image of a term with respect to an injective function, primarily working with symbolic representations of terms and their transformation rules. It provides operations to retrieve inverse mappings for constant and product terms, leveraging cached rule graphs to efficiently determine original inputs from transformed outputs. Concrete use cases include reversing term reductions in a rewriting system and reconstructing source terms from their normalized forms.",
      "description_length": 493,
      "index": 34,
      "embedding_norm": 0.9999999403953552
    },
    {
      "module_path": "Core.Version",
      "library": "lambdapi.core",
      "description": "This module provides a single value `version` that returns a string containing version information. It works with string data to expose the current version of the library or application. A concrete use case is displaying the version number in command-line interfaces or logs for debugging and identification purposes.",
      "description_length": 317,
      "index": 35,
      "embedding_norm": 0.9999999403953552
    },
    {
      "module_path": "Core.Term",
      "library": "lambdapi.core",
      "description": "This module represents terms in a typed lambda calculus with support for binders, metavariables, and patterns, using Bindlib-based structures like `tbox` and `tbinder` for safe substitution and variable management. It enables operations such as term construction, unification, normalization, and inspection, with direct use in proof assistants and term rewriting systems. Submodules provide ordered sets and maps for variables, symbols, and metavariables, supporting efficient set algebra, ordered traversal, and environment management. Specific capabilities include tracking variable dependencies, managing symbol tables, and printing terms for debugging.",
      "description_length": 656,
      "index": 36,
      "embedding_norm": 1.0
    },
    {
      "module_path": "Core.Ctxt",
      "library": "lambdapi.core",
      "description": "This module manages typing contexts, providing operations to query variable types, definitions, and existence within a context. It supports term manipulation by abstracting over contexts, unfolding definitions, and decomposing terms with context substitutions. Use cases include type checking, term normalization, and context-based term transformations in a lambda calculus or proof assistant setting.",
      "description_length": 401,
      "index": 37,
      "embedding_norm": 1.0
    },
    {
      "module_path": "Core.Sign",
      "library": "lambdapi.core",
      "description": "This component provides operations to manage symbol definitions, including adding and resolving notations, built-in constructs, and inductive types within a formal system. It manipulates signature structures that track symbol metadata like constructors, induction rules, and module dependencies, supporting serialization and dependency traversal. Key use cases involve maintaining consistent symbol mappings during theorem proving tasks and ensuring referential integrity across logical expressions.",
      "description_length": 499,
      "index": 38,
      "embedding_norm": 1.0
    },
    {
      "module_path": "Core.Infer",
      "library": "lambdapi.core",
      "description": "This module performs type inference and checking for terms in a given context, refining terms and determining their types or checking against expected types. It works with terms and contexts from the Core.Term module, handling metavariables and constraints during inference. Concrete use cases include validating term correctness in a typed logic system and supporting interactive proof assistants by resolving implicit type information.",
      "description_length": 437,
      "index": 39,
      "embedding_norm": 1.0
    },
    {
      "module_path": "Core.Ghost",
      "library": "lambdapi.core",
      "description": "This module defines a ghost signature used by the kernel, including operations to check membership and iterate over ghost symbols. It works with symbolic terms and paths, providing direct access to the signature's structure. Concrete use cases include managing internal symbols that are not user-defined, such as those generated during type checking or compilation.",
      "description_length": 365,
      "index": 40,
      "embedding_norm": 1.0
    },
    {
      "module_path": "Core.Eval",
      "library": "lambdapi.core",
      "description": "This module evaluates and converts terms according to various reduction strategies, including weak head-normal form, head-normal form, and strong normal form. It supports operations like beta-reduction, eta-equality, and unfolding of symbol definitions, working with terms in a given context. Use cases include normalizing lambda calculus expressions, checking term convertibility, and simplifying terms during type checking or proof construction.",
      "description_length": 447,
      "index": 41,
      "embedding_norm": 1.0
    },
    {
      "module_path": "Core.LibMeta",
      "library": "lambdapi.core",
      "description": "This module provides functions to create, manage, and manipulate metavariables within a term problem. It supports operations such as generating fresh metavariables, setting their values, and checking their occurrence in terms, working directly with term contexts, boxed terms, and metavariable binders. Use cases include constructing and modifying terms with unresolved metavariables during type checking or rewriting, particularly when managing dependencies between terms and their typing contexts.",
      "description_length": 499,
      "index": 42,
      "embedding_norm": 0.9999999403953552
    },
    {
      "module_path": "Core.Print",
      "library": "lambdapi.core",
      "description": "This module provides pretty-printing operations for terms, symbols, variables, and notations in the Core AST, along with dynamic configuration options to control output behavior for domains, implicits, and metavariables. It operates on terms, contexts, constraints, and type-checking states to support debugging and logging during term type-checking, error analysis, and convertibility testing. The functionality is specifically used for generating human-readable feedback in success or failure scenarios and for inspecting term structures during development.",
      "description_length": 559,
      "index": 43,
      "embedding_norm": 0.9999999403953552
    },
    {
      "module_path": "Core.Tree",
      "library": "lambdapi.core",
      "description": "This module compiles rewriting rules into decision trees using Maranget's method, transforming rule sets into executable logic for efficient pattern matching. It organizes terms and rules into clause matrices, selecting optimal patterns for specialization while managing constraints through integer maps and arrays to track variables and conditions. The system supports operations like exhaustiveness checks, wildcard filtering, and substitution application, enabling concrete use cases such as optimizing term rewriting in functional language compilers. Constraint submodules handle persistent set operations on integer pairs, ensuring correct condition coverage and partitioning during compilation.",
      "description_length": 700,
      "index": 44,
      "embedding_norm": 1.0
    },
    {
      "module_path": "Core.Builtin",
      "library": "lambdapi.core",
      "description": "This module manages built-in symbols by providing operations to register and retrieve them, along with associated type-checking functions. It works with signature states, symbol tables, and terms to enforce correct usage of built-in names during type checking. Concrete use cases include validating that a built-in symbol has the correct type when loaded and registering custom type checks for specific built-in identifiers.",
      "description_length": 424,
      "index": 45,
      "embedding_norm": 1.0
    },
    {
      "module_path": "Core.Env",
      "library": "lambdapi.core",
      "description": "This module manages variable scoping environments as associative lists mapping variable names to tuples of variables, types, and optional definitions. It supports operations to construct and deconstruct dependent product terms, abstract terms, and applications using environment-bound variables, and to convert environments to contexts or arrays. Concrete use cases include unbinding nested products in terms, building lambda abstractions from environments, and applying terms to sequences of variables.",
      "description_length": 503,
      "index": 46,
      "embedding_norm": 1.0
    },
    {
      "module_path": "Core.Coercion",
      "library": "lambdapi.core",
      "description": "This module implements term coercion logic using a symbolic representation for coercion rules. It provides operations to define coercion functions via `coerce` and apply them to terms with `apply`, transforming values between types. Direct use cases include implementing type conversions in term rewriting systems or proof assistants where explicit coercion steps are required.",
      "description_length": 377,
      "index": 47,
      "embedding_norm": 1.0
    },
    {
      "module_path": "Core.Unif_rule",
      "library": "lambdapi.core",
      "description": "This module defines symbols and operations for handling unification rules in a ghost signature. It provides the `equiv` and `cons` symbols to represent equality and rule composition, along with functions to unpack and check membership of terms. It is used to manipulate lists of equivalence constraints in unification problems.",
      "description_length": 327,
      "index": 48,
      "embedding_norm": 1.0
    },
    {
      "module_path": "Core.Unif",
      "library": "lambdapi.core",
      "description": "Simplifies unification constraints in a given problem, returning whether all constraints are satisfiable. It operates on `Core.Term.problem` structures, modifying their `to_solve` and `unsolved` fields based on the simplification results. Useful in type inference systems where metavariables need to be resolved while optionally enforcing type correctness during instantiation.",
      "description_length": 377,
      "index": 49,
      "embedding_norm": 0.9999999403953552
    },
    {
      "module_path": "Core",
      "library": "lambdapi.core",
      "description": "This module provides a comprehensive framework for term manipulation, type checking, and rewriting within a typed lambda calculus. It centers on terms, contexts, metavariables, and symbols, offering operations for term traversal, substitution, unification, normalization, and pretty-printing, along with support for decision trees, coercion, and inverse term mapping. Users can perform tasks such as analyzing and rewriting lambda terms, inferring and checking types in a context-aware environment, compiling pattern-matching rules into efficient decision structures, and managing symbol definitions and scoping during theorem proving or compilation. Specific examples include normalizing terms using beta-reduction, reconstructing source expressions from transformed outputs, and resolving qualified identifiers during term printing.",
      "description_length": 834,
      "index": 50,
      "embedding_norm": 1.0
    },
    {
      "module_path": "Lsp.Lsp_base",
      "library": "lambdapi.lsp",
      "description": "This module constructs and manipulates JSON objects for communication in a language server protocol. It converts positions, goals, and diagnostics into JSON format, supporting responses to client requests. It works with positions, goals, and diagnostic data to generate structured JSON replies for features like error reporting and goal display.",
      "description_length": 345,
      "index": 51,
      "embedding_norm": 0.9999999403953552
    },
    {
      "module_path": "Lsp.Lp_lsp",
      "library": "lambdapi.lsp",
      "description": "Implements a command-line interface for launching a language server, accepting a boolean flag to enable verbose logging and a string argument for the log file path. Works directly with string values and boolean flags to configure runtime behavior. Used to start a language server process with customizable log output destination and level of detail.",
      "description_length": 349,
      "index": 52,
      "embedding_norm": 0.9999999403953552
    },
    {
      "module_path": "Lsp.Lsp_io",
      "library": "lambdapi.lsp",
      "description": "This module handles input/output operations for LSP (Language Server Protocol) communication. It provides functions to read JSON requests from an input channel, send formatted JSON responses, and log errors or JSON objects with descriptive messages. It works directly with JSON values (`J.t`), formatters (`F.formatter`), and standard I/O channels.",
      "description_length": 348,
      "index": 53,
      "embedding_norm": 1.0
    },
    {
      "module_path": "Lsp.Lp_doc",
      "library": "lambdapi.lsp",
      "description": "This module manages document state and proof processing for a logical editor, handling operations like command execution, goal tracking, and error reporting. It works with document nodes containing commands, proof states, and associated metadata, along with log entries and position mappings. Concrete use cases include parsing and evaluating proof scripts, maintaining document versions, and generating error responses tied to specific positions in the document.",
      "description_length": 463,
      "index": 54,
      "embedding_norm": 0.9999999403953552
    },
    {
      "module_path": "Lsp",
      "library": "lambdapi.lsp",
      "description": "This module facilitates communication and state management for a language server, handling JSON serialization, document processing, and input/output operations. It defines core data types like JSON values (`J.t`), document nodes, and position mappings, with operations to serialize goals and diagnostics, read and respond to LSP requests, and manage proof script evaluation. You can use it to launch a language server with logging, process document changes and commands, and exchange structured data with a client over standard I/O channels.",
      "description_length": 541,
      "index": 55,
      "embedding_norm": 0.9999999403953552
    },
    {
      "module_path": "Export.Coq.QidMap",
      "library": "lambdapi.export",
      "description": "This module implements a polymorphic key-value map with `Qid.t` identifiers as keys, supporting operations like insertion, deletion, traversal, and transformation with both functional and list-based value manipulations. It provides sequence-based conversion, reverse iteration, and filtering capabilities, emphasizing safe access through optional return types and conditional updates. Designed for managing identifier mappings during AST translation, it facilitates tasks like renaming, merging, and encoding structured data in Coq's type system.",
      "description_length": 546,
      "index": 56,
      "embedding_norm": 1.0
    },
    {
      "module_path": "Export.Hrs.VMap",
      "library": "lambdapi.export",
      "description": "This module provides a map structure for managing variable bindings with operations to transform, filter, and traverse key-value pairs, along with sequence-based construction and ordered iteration. It works with keys representing HRS-translated variables (positive integers for bound variables, \"$\"-prefixed identifiers for pattern variables) and arbitrary typed values, supporting use cases like tracking variable arities during lambda term translation, ensuring name uniqueness in HRS output, and optimizing symbol usage by filtering unused bindings before serialization. The sequence conversion functions enable incremental map updates and ordered traversal required for deterministic HRS term generation.",
      "description_length": 708,
      "index": 57,
      "embedding_norm": 1.0
    },
    {
      "module_path": "Export.Coq.Qid",
      "library": "lambdapi.export",
      "description": "Translates qualified identifiers from the parser-level AST to Coq, supporting both raw Coq and simple type theory encodings. It handles identifier renaming via a provided map and is used during AST translation to ensure correct name resolution in the target Coq output. This module is essential for mapping source identifiers to their corresponding Coq representations in either translation mode.",
      "description_length": 396,
      "index": 58,
      "embedding_norm": 1.0
    },
    {
      "module_path": "Export.Hrs.V",
      "library": "lambdapi.export",
      "description": "This module manages pattern variable naming and arity tracking for HRS format translation. It uses a map to associate pattern variable names with their arities, ensuring correct prefixing and uniqueness across rules. It supports operations to add, look up, and compare pattern variables based on rule-specific naming conventions.",
      "description_length": 329,
      "index": 59,
      "embedding_norm": 1.0
    },
    {
      "module_path": "Export.Rawdk",
      "library": "lambdapi.export",
      "description": "This module provides translation and transformation operations for converting abstract syntax trees (ASTs) into Dedukti terms, focusing on removing syntactic layers, processing term modifiers, and mapping annotated types. It works with parser-level ASTs, identifiers, terms, parameters, and assertions, employing structured patterns to handle constructs like let-bindings, abstractions, and products. The functionality supports use cases such as flattening complex syntax trees into Dedukti representations and extracting type information from annotated expressions.",
      "description_length": 566,
      "index": 60,
      "embedding_norm": 1.0
    },
    {
      "module_path": "Export.Hrs",
      "library": "lambdapi.export",
      "description": "The module translates Lambdapi signatures into the HRS term algebra, using specific symbols for application, lambda abstraction, let, and \u03a0 types, while managing naming constraints such as distinct variable and function symbol namespaces, arity-based encoding of pattern variables, and rule-specific prefixes. It coordinates with a variable binding map to track and transform variable names and arities during translation, ensuring deterministic output and optimized symbol usage. The pattern variable module enforces unique naming and arity tracking across rules, enabling correct HRS serialization. Example usage includes converting a LambdaPi term with pattern variables and nested lambdas into a Unicode-free HRS term with numbered bound variables and rule-prefixed pattern identifiers.",
      "description_length": 790,
      "index": 61,
      "embedding_norm": 0.9999999403953552
    },
    {
      "module_path": "Export.Dk",
      "library": "lambdapi.export",
      "description": "This module translates terms and declarations between Lambdapi and Dedukti syntax, focusing on identifier escaping to avoid Dedukti keywords, path normalization, and syntactic formatting. It operates on terms, declarations, and signatures while managing dependencies through require statements, ensuring compatibility between the two systems. Key applications include converting Lambdapi signatures into valid Dedukti files and programmatically resolving identifier conflicts during cross-language interoperability tasks.",
      "description_length": 521,
      "index": 62,
      "embedding_norm": 1.0
    },
    {
      "module_path": "Export.Coq",
      "library": "lambdapi.export",
      "description": "This module translates parser-level ASTs into Coq syntax using two modes: raw translation, which directly maps lambda calculus constructs to Coq, and STT encoding, which embeds the AST into simple type theory using an external specification. It processes structured terms and identifiers, applying renaming maps to transform symbols during translation, ensuring compatibility with Coq's naming and type system. The module relies on a key-value map for managing identifier transformations and a dedicated identifier translator that applies renaming rules in both raw and STT modes. These components together enable precise Coq output generation, supporting use cases such as formal verification and lambda calculus embedding.",
      "description_length": 724,
      "index": 63,
      "embedding_norm": 1.0
    },
    {
      "module_path": "Export.Xtc",
      "library": "lambdapi.export",
      "description": "This module translates simply typed LambdaPi terms and signatures into the XTC format used for termination analysis competitions, handling symbols, bound variables, pattern variables, and rewrite rules. It supports extended XTC features like lambda and application in types, generating output for tools such as SizeChangeTool that consume type-level rules and termination certificates. Key use cases include exporting formalized type theories and rewrite systems to standardized XML-based formats for automated termination checking.",
      "description_length": 532,
      "index": 64,
      "embedding_norm": 1.0
    },
    {
      "module_path": "Export",
      "library": "lambdapi.export",
      "description": "This collection translates and transforms abstract syntax trees into various target formats, including Dedukti, HRS, Coq, and XTC, by processing identifiers, terms, types, and declarations through structured mappings and renaming strategies. It supports operations such as flattening complex syntax, encoding pattern variables with arity tracking, escaping reserved keywords, and embedding lambda terms into type theories. Specific applications include converting LambdaPi terms into Unicode-free HRS representations, generating valid Coq files from signatures, and exporting rewrite systems to XTC for termination analysis. The system ensures deterministic output through binding maps, renaming rules, and structured pattern handling across multiple translation modes.",
      "description_length": 769,
      "index": 65,
      "embedding_norm": 1.0
    },
    {
      "module_path": "Lplib.RangeMap.Make.Range",
      "library": "lambdapi.lplib",
      "description": "This module represents and manipulates source code positions and intervals using line and column numbers. It provides operations to create and compare intervals, check if a point lies within an interval, and translate interval boundaries. Concrete use cases include tracking token positions in a parser or managing source code spans for error reporting.",
      "description_length": 353,
      "index": 66,
      "embedding_norm": 1.0
    },
    {
      "module_path": "Lplib.Option.Monad",
      "library": "lambdapi.lplib",
      "description": "This module provides monadic operations for working with `option` values, specifically enabling sequential composition of functions that may fail using `let*` and wrapping values in `option` context with `return`. It supports chaining optional computations without explicit pattern matching, improving readability and reducing boilerplate. Use it to handle sequences of operations where any step may fail, such as parsing nested data or querying optional fields.",
      "description_length": 462,
      "index": 67,
      "embedding_norm": 0.9999999403953552
    },
    {
      "module_path": "Lplib.RangeMap.Make",
      "library": "lambdapi.lplib",
      "description": "This module implements a map from intervals to values with efficient point lookup, supporting operations to add intervals with associated values and query which intervals contain a given point. It combines core functionality for managing overlapping or nested regions with submodules that provide concrete representations of source code positions and intervals using line and column numbers. You can use it to track token ranges in a parser, manage source code spans for error reporting, or model dynamic memory or text regions where intervals may change over time. The API allows creating, comparing, and translating intervals, as well as checking containment and querying active intervals at specific points.",
      "description_length": 710,
      "index": 68,
      "embedding_norm": 1.0
    },
    {
      "module_path": "Lplib.Option.Applicative",
      "library": "lambdapi.lplib",
      "description": "This module implements applicative functors for the `option` type, enabling function application within the context of optional values. It provides `pure` to wrap values in an `option` and `<*>` to apply an optional function to an optional argument, propagating absence. Use it to compose operations that depend on the presence of values without explicit pattern matching, such as combining optional configuration parameters or chaining safe arithmetic operations.",
      "description_length": 464,
      "index": 69,
      "embedding_norm": 1.0
    },
    {
      "module_path": "Lplib.Extra.IntSet",
      "library": "lambdapi.lplib",
      "description": "This module implements integer set operations for membership testing, set algebra, and element manipulation, offering functions like union, intersection, and difference alongside safe accessors for minimum/maximum elements. It works with abstract integer sets and supports conversions to and from lists and sequences, enabling efficient iteration, filtering, and transformation workflows. Typical use cases include deduplicating integer collections, analyzing set relationships, and processing integer ranges with ordered traversal.",
      "description_length": 532,
      "index": 70,
      "embedding_norm": 1.0
    },
    {
      "module_path": "Lplib.Extra.StrSet",
      "library": "lambdapi.lplib",
      "description": "This module implements set algebra operations (union, intersection, difference) and element management (insertion, removal, membership checks) for string collections, along with transformations like mapping, filtering, and partitioning. It operates on immutable string sets and supports conversions to and from lists and sequences, enabling use cases such as data aggregation, unique element extraction, and iterative processing in pipelines.",
      "description_length": 442,
      "index": 71,
      "embedding_norm": 1.0
    },
    {
      "module_path": "Lplib.RangeMap_intf.S-Range",
      "library": "lambdapi.lplib",
      "description": "This module represents and manipulates source code intervals defined by start and end positions. It provides operations to create intervals from line and column points, check point inclusion within intervals, translate interval bounds, and compare intervals. Concrete use cases include tracking source code spans in compilers or static analysis tools, and managing text buffer selections with precise line and column offsets.",
      "description_length": 425,
      "index": 72,
      "embedding_norm": 0.9999999403953552
    },
    {
      "module_path": "Lplib.Base.Int",
      "library": "lambdapi.lplib",
      "description": "This module provides arithmetic operations, bitwise manipulations, and numeric comparisons for 32-bit and 64-bit integers. It includes functions for addition, subtraction, multiplication, division, modulus, shifting, and bitwise AND/OR/XOR. Concrete use cases include low-level numeric computations, bitmask handling, and integer-based state transitions in performance-sensitive code.",
      "description_length": 384,
      "index": 73,
      "embedding_norm": 1.0
    },
    {
      "module_path": "Lplib.Range_intf.S",
      "library": "lambdapi.lplib",
      "description": "This module defines operations for creating and manipulating points and intervals, primarily used to determine whether a cursor position lies within a specific token range. It provides functions to construct points from line and column numbers, create intervals with start and end points, and check the relative position of a point to an interval. Additional operations include interval comparison, string representation, and translation of interval bounds by specified deltas.",
      "description_length": 477,
      "index": 74,
      "embedding_norm": 1.0
    },
    {
      "module_path": "Lplib.RangeMap_intf.S",
      "library": "lambdapi.lplib",
      "description": "Implements a map from intervals to values, where each interval is non-overlapping and uniquely identifies a value. Supports operations to add a mapping, look up a value by point, and convert the structure to a string. Useful for tracking source code positions with tokens or associating values with non-overlapping numeric ranges.",
      "description_length": 330,
      "index": 75,
      "embedding_norm": 1.0
    },
    {
      "module_path": "Lplib.Array",
      "library": "lambdapi.lplib",
      "description": "This module offers a comprehensive suite of operations for array and matrix manipulation, including creation (e.g., `make`, `init`), indexed transformations (`map_inplace`, `mapi`), functional reductions (`fold_left`, `find_opt`), and structural adaptations (`append`, `split`). It operates on polymorphic arrays and matrices, supporting both in-place mutations and pure functional transformations, with utilities for sorting, shuffling, and equality checks. These capabilities are particularly useful for numerical computations, data processing pipelines, and algorithms requiring precise control over array elements or their indices.",
      "description_length": 635,
      "index": 76,
      "embedding_norm": 1.0
    },
    {
      "module_path": "Lplib.Range",
      "library": "lambdapi.lplib",
      "description": "This module represents and manipulates source code positions and intervals. It defines points as line and column pairs, and intervals as start and end points, providing operations to create, compare, and translate them. It is used to track and query the location of code elements in a text buffer, such as during parsing or analysis.",
      "description_length": 333,
      "index": 77,
      "embedding_norm": 1.0
    },
    {
      "module_path": "Lplib.Base",
      "library": "lambdapi.lplib",
      "description": "This module extends the standard library with tools for creating custom pretty-printers and comparison functions, allowing developers to compose formatters with prefixes, suffixes, or conditional elements, and to define orderings lexicographically or through mapped values. It also includes a child module for efficient 32-bit and 64-bit integer arithmetic, bitwise operations, and numeric comparisons, enabling low-level numeric processing and bitmask manipulations. Together, they support tasks like generating structured output for complex data types while handling integer-based computations with precision and performance. Example uses include formatting nested data structures with consistent syntax and implementing custom sorting logic over composite keys or bitmasked values.",
      "description_length": 784,
      "index": 78,
      "embedding_norm": 1.0
    },
    {
      "module_path": "Lplib.Color",
      "library": "lambdapi.lplib",
      "description": "This module defines operations for handling colored output in formatted strings, supporting ANSI color codes through a variant type representing basic colors. It provides functions to convert colors to strings and codes, apply color tags to format strings, and dynamically update formatters to include color. Specific use cases include coloring terminal output based on type or status, such as highlighting errors in red or success messages in green.",
      "description_length": 450,
      "index": 79,
      "embedding_norm": 1.0
    },
    {
      "module_path": "Lplib.RangeMap_intf",
      "library": "lambdapi.lplib",
      "description": "This module defines an interface for mapping intervals to values, enabling efficient insertion, deletion, and lookup over ordered ranges such as integers or timestamps. It supports core operations like querying overlapping ranges, inserting non-overlapping intervals, and associating values with precise spans. The first child module specializes in source code intervals, offering creation, comparison, and inclusion checks for line and column-based ranges, while the second implements a concrete interval-to-value map for non-overlapping ranges, supporting point-based lookups and string representation. Together, they enable use cases like tracking memory regions, managing text selections, and associating metadata with source code spans.",
      "description_length": 741,
      "index": 80,
      "embedding_norm": 1.0
    },
    {
      "module_path": "Lplib.Bytes",
      "library": "lambdapi.lplib",
      "description": "This module enables low-level byte sequence manipulation through operations like slicing, concatenation, and in-place updates, while supporting character-level transformations such as case conversion, predicate checks, and whitespace trimming. It handles binary data parsing/serialization with endianness-aware integer encoding, UTF-8/UTF-16 validation, and Unicode character manipulation, making it suitable for tasks like protocol implementation, file format parsing, and encoding conversion. The core `bytes` type serves as the foundation for both ASCII and Unicode-aware operations, with utilities for safe/unsafe memory access and sequence traversal.",
      "description_length": 655,
      "index": 81,
      "embedding_norm": 0.9999999403953552
    },
    {
      "module_path": "Lplib.Option",
      "library": "lambdapi.lplib",
      "description": "This module provides a comprehensive set of tools for working with optional values, combining direct functions for creation, transformation, and inspection with monadic and applicative submodules for composing computations that may fail. The core functionality includes operations like `map`, `bind`, and `get`, while the monadic submodule enables sequential chaining with `let*` and the applicative submodule supports function application with `<*>`. It allows tasks such as safely processing nested data structures, combining optional configuration values, or handling missing input without repetitive pattern matching. The integration with pretty-printing and conversions to other types like `result` or sequences further supports robust error handling and data flow in parsing, configuration, and general application logic.",
      "description_length": 827,
      "index": 82,
      "embedding_norm": 1.0
    },
    {
      "module_path": "Lplib.RangeMap",
      "library": "lambdapi.lplib",
      "description": "This module manages a collection of non-overlapping intervals mapped to values, enabling efficient point-based lookups and interval insertions. It supports core operations like adding intervals, querying values at specific points, and converting the structure to a string, while its submodules enhance functionality with concrete representations of source code positions and interval manipulations. You can use it to track token ranges during parsing, associate metadata with file regions, or manage dynamic memory or text segments. The API also includes utilities for interval comparison, translation, and containment checks, enabling precise handling of nested or overlapping regions.",
      "description_length": 686,
      "index": 83,
      "embedding_norm": 1.0
    },
    {
      "module_path": "Lplib.Filename",
      "library": "lambdapi.lplib",
      "description": "This module provides path concatenation, extension stripping, and temporary file creation with customizable prefixes, suffixes, and permissions, alongside utilities for resolving implicit paths, normalizing hierarchies, and safely quoting command-line arguments. It operates on file paths and directory structures, emphasizing cross-platform safety and precision in handling absolute/relative paths, base names, and directory components. Typical applications include cross-platform file management tools, secure temporary resource handling, and scripts requiring reliable path manipulation or directory traversal.",
      "description_length": 613,
      "index": 84,
      "embedding_norm": 0.9999999403953552
    },
    {
      "module_path": "Lplib.Extra",
      "library": "lambdapi.lplib",
      "description": "This module provides high-performance map and set implementations for integers and strings, along with utilities for file handling, time measurement, and path traversal. It supports operations like union, intersection, and difference on integer and string sets, with safe accessors and conversions to lists and sequences for efficient iteration and transformation. Functions such as `get_safe_prefix`, `with_timeout`, and `more_recent` enable tasks like generating unique strings, enforcing time limits, and tracking file dependencies. These capabilities are useful for managing temporary files, implementing build systems, and processing integer or string collections with set algebra.",
      "description_length": 686,
      "index": 85,
      "embedding_norm": 0.9999999403953552
    },
    {
      "module_path": "Lplib.Range_intf",
      "library": "lambdapi.lplib",
      "description": "This module provides core operations for working with integer ranges, enabling iteration, mapping, and folding over bounded intervals, along with efficient traversal and transformation of range-based sequences. It includes a child module for handling points and intervals, allowing construction from line and column numbers, interval comparison, and checking point inclusion. Together, they support tasks like generating indexed data structures, performing calculations over discrete intervals, and managing cursor positions within token ranges. For example, you can iterate over a range to build an array of values or determine if a cursor lies within a specific source code token.",
      "description_length": 682,
      "index": 86,
      "embedding_norm": 1.0
    },
    {
      "module_path": "Lplib.List",
      "library": "lambdapi.lplib",
      "description": "This module implements comprehensive list manipulation capabilities centered on traversal, transformation, filtering, and structural comparison operations. It operates on generic OCaml lists, associative lists (key-value pairs), sequences, and array combinations, supporting indexed processing, accumulator threading, and predicate-driven computations. Specific applications include data processing pipelines with `filter_map` and `fold_left_map`, associative key-value lookups with custom equality, sorted list maintenance with `insert_sorted`, and efficient list merging or deduplication while preserving order or uniqueness constraints.",
      "description_length": 639,
      "index": 87,
      "embedding_norm": 0.9999999403953552
    },
    {
      "module_path": "Lplib.Uchar",
      "library": "lambdapi.lplib",
      "description": "This module provides operations for validating, converting, and manipulating Unicode scalar values represented as integers, including handling special constants like BOM and replacement characters. It supports working with UTF-8 and UTF-16 encoded byte sequences through decoding, validation, and measurement functions, while offering safe and unsafe conversion utilities with explicit error handling. These capabilities are useful for low-level Unicode processing, encoding-aware text validation, and handling invalid or malformed character sequences in structured data.",
      "description_length": 571,
      "index": 88,
      "embedding_norm": 1.0
    },
    {
      "module_path": "Lplib",
      "library": "lambdapi.lplib",
      "description": "This module provides a rich set of utilities for data structure manipulation, source code tracking, numeric computation, and text processing. Core data types include arrays, matrices, intervals, bytes, optional values, and Unicode scalars, with operations spanning functional transformations, in-place mutations, and structured formatting. It supports tasks like numerical computations with matrices, source code analysis using intervals and positions, low-level byte and Unicode handling, and robust error handling with optional values. Specific examples include formatting structured data with colored output, tracking memory or text regions using interval maps, and implementing custom pretty-printers or comparison logic for complex types.",
      "description_length": 743,
      "index": 89,
      "embedding_norm": 1.0
    },
    {
      "module_path": "Common.Debug.D",
      "library": "lambdapi.common",
      "description": "This module provides functions for logging values and control flow during debugging, including utilities to print primitive types, collections, and custom data structures. It supports operations like logging and returning a value, logging and raising exceptions, and formatting complex types such as lists, arrays, maps, and pairs. Concrete use cases include tracing function inputs/outputs, inspecting data structures during execution, and debugging error paths with contextual information.",
      "description_length": 491,
      "index": 90,
      "embedding_norm": 1.0
    },
    {
      "module_path": "Common.Path.Path",
      "library": "lambdapi.common",
      "description": "This module represents and manipulates module paths as string lists. It provides `pp` for printing paths to a formatter and `compare` for ordering paths lexicographically. These operations are used internally within the Common module to handle path identifiers without escaping special characters.",
      "description_length": 297,
      "index": 91,
      "embedding_norm": 1.0
    },
    {
      "module_path": "Common.Path.Map",
      "library": "lambdapi.common",
      "description": "This module implements a specialized ordered map structure for associating file paths with arbitrary data, supporting both functional and imperative manipulation. It provides operations for precise path-based lookups (including first/last selection), ordered traversal, bulk updates from sequences, and structural transformations like merging or filtering. Typical applications include managing hierarchical path-based configurations, tracking file dependencies, or organizing path-indexed metadata with efficient ordered access.",
      "description_length": 529,
      "index": 92,
      "embedding_norm": 1.0
    },
    {
      "module_path": "Common.Library.LibMap",
      "library": "lambdapi.common",
      "description": "This module manages mappings between module paths and file paths, supporting operations to add, retrieve, and iterate over bindings. It works with module paths (`Common.Path.t`) and string file paths, maintaining a mapping structure internally. It is used to track which files correspond to specific module paths within a library, enabling resolution of modules to their source files during compilation or debugging.",
      "description_length": 416,
      "index": 93,
      "embedding_norm": 1.0
    },
    {
      "module_path": "Common.Path.Set",
      "library": "lambdapi.common",
      "description": "This module provides a functional set interface for managing collections of file or directory paths, supporting operations like union, intersection, filtering, and ordered traversal. It works with sets of `Common.Path.Path.t` values, enabling efficient membership checks, conditional transformations, and conversions to/from lists or sequences. Typical use cases include path deduplication, hierarchical directory traversal analysis, and batch operations on file system entities.",
      "description_length": 479,
      "index": 94,
      "embedding_norm": 1.0
    },
    {
      "module_path": "Common.Console.State",
      "library": "lambdapi.common",
      "description": "This module manages the imperative state of the typechecker, including verbosity levels, enabled loggers, and boolean flags. It provides operations to save, restore, and apply specific states, enabling precise control during typechecking phases. Concrete use cases include temporarily changing logging behavior or flag settings during type inference and reverting them afterward.",
      "description_length": 379,
      "index": 95,
      "embedding_norm": 1.0
    },
    {
      "module_path": "Common.Library",
      "library": "lambdapi.common",
      "description": "This module organizes library paths and mappings between module paths and file paths, enabling conversion, validation, and resolution of source and object files. It supports operations like adding validated module-to-file bindings, iterating over existing mappings, and determining correct file paths from module paths with proper extensions. The internal mapping structure tracks associations using `Common.Path.t` for modules and strings for files, facilitating tasks like setting up a library root, linking module names to source files, and locating files during compilation. It integrates direct management of library roots and file extensions with submodules that handle binding storage and lookup.",
      "description_length": 703,
      "index": 96,
      "embedding_norm": 0.9999999403953552
    },
    {
      "module_path": "Common.Pos",
      "library": "lambdapi.common",
      "description": "This module enables comparing, merging, and adjusting source code positions, along with mapping over located values and converting Lexing positions. It operates on `pos` records that store file names and UTF-8 line/column ranges, paired with `loc` values to associate elements to their positions. These utilities are used in compiler toolchains to track source locations, report errors with contextual code snippets, and sanitize output through custom delimiters and escape functions.",
      "description_length": 484,
      "index": 97,
      "embedding_norm": 1.0
    },
    {
      "module_path": "Common.Console",
      "library": "lambdapi.common",
      "description": "This module manages logging output and verbosity settings, providing functions to control message display based on severity levels and to register and manipulate boolean flags. It supports operations to save, restore, and apply specific states, enabling precise control during typechecking phases. Main data types include integers for verbosity levels, formatter objects for output handling, and string-indexed boolean flags with timed references. Concrete use cases include conditionally printing log messages, setting up configurable debug switches, temporarily changing logging behavior during type inference, and resetting state to defaults during initialization or testing.",
      "description_length": 678,
      "index": 98,
      "embedding_norm": 1.0
    },
    {
      "module_path": "Common.Logger",
      "library": "lambdapi.common",
      "description": "This module manages configurable logging with per-key enable/disable controls and output formatting. It provides functions to create and register loggers with associated keys, names, and descriptions, and to conditionally execute logging based on runtime debug settings. Use cases include selectively enabling debug logs during development and generating summaries of available logging options for user documentation.",
      "description_length": 417,
      "index": 99,
      "embedding_norm": 0.9999999403953552
    },
    {
      "module_path": "Common.Error",
      "library": "lambdapi.common",
      "description": "This module handles warning and error reporting with formatted output, including position information and color coding. It supports operations for printing warnings, building fatal error messages, and raising exceptions with structured formatting. Use cases include reporting parse errors with source positions, displaying user warnings during compilation, and handling unrecoverable errors in the main program loop.",
      "description_length": 416,
      "index": 100,
      "embedding_norm": 1.0
    },
    {
      "module_path": "Common.Path",
      "library": "lambdapi.common",
      "description": "This module represents module paths as string lists, offering core operations like pretty-printing with `pp` and lexicographic ordering via `compare`, while supporting ghost path creation for internal use in path identifier management. It includes a map submodule for associating file paths with data, enabling functional and imperative updates, ordered traversal, and structural transformations like merging, alongside a set submodule for managing path collections with union, intersection, and efficient membership checks. These components work together to manage hierarchical configurations, track dependencies, and perform batch file system operations. Example uses include organizing path-based metadata, deduplicating directory paths, and maintaining ordered file dependency graphs.",
      "description_length": 788,
      "index": 101,
      "embedding_norm": 1.0
    },
    {
      "module_path": "Common.Escape",
      "library": "lambdapi.common",
      "description": "This module handles string manipulation for identifiers that may be escaped using the \"{|...|}\" syntax. It provides functions to escape a string, check if it is already escaped, and remove escape markers, along with utilities to safely prepend or append to identifiers while preserving escape semantics. It is used when generating or transforming identifiers in contexts where name mangling or escaping is required, such as in code generation or parsing.",
      "description_length": 454,
      "index": 102,
      "embedding_norm": 1.0
    },
    {
      "module_path": "Common.Debug",
      "library": "lambdapi.common",
      "description": "This module combines time measurement and logging capabilities to help analyze and debug programs. It allows timing specific stages of a process and logging values, control flow, and errors with detailed formatting. You can, for example, track the duration of a parsing phase while logging intermediate data structures like lists or pairs at each step. The module also supports custom log handlers and integrates stream processing with time tracking for debugging performance-critical pipelines.",
      "description_length": 495,
      "index": 103,
      "embedding_norm": 1.0
    },
    {
      "module_path": "Common",
      "library": "lambdapi.common",
      "description": "This module provides utilities for path management, source location tracking, logging control, and string manipulation in a compiler or toolchain environment. Key data types include module paths, source positions, verbosity levels, and escaped identifiers, with operations for mapping modules to files, comparing code locations, configuring log output, and handling warnings with color-coded formatting. It enables tasks like resolving source file paths from module names, logging debug information with dynamic filtering, measuring performance of compilation stages, and escaping identifiers during code generation. Example uses include tracking dependencies in a build system, reporting syntax errors with precise source positions, and selectively enabling verbose output during typechecking.",
      "description_length": 794,
      "index": 104,
      "embedding_norm": 1.0
    },
    {
      "module_path": "Tool.Tree_graphviz",
      "library": "lambdapi.tool",
      "description": "This module converts decision trees represented as `Core.Term.dtree` into Graphviz's DOT format for visualization. It defines the `dot_term` type to model node labels and supports rendering trees where nodes represent pattern matrices and edges represent matched terms. Use it to generate visual representations of decision trees for debugging or documentation purposes.",
      "description_length": 370,
      "index": 105,
      "embedding_norm": 0.9999999403953552
    },
    {
      "module_path": "Tool.External",
      "library": "lambdapi.tool",
      "description": "This module runs external checkers via Unix commands to validate signatures, using a provided formatter to process input and parsing the checker's output for results. It supports string-based commands, custom output formatting, and returns tri-state outcomes (true, false, or inconclusive). Concrete use cases include integrating third-party signature verification tools into a build or validation pipeline.",
      "description_length": 407,
      "index": 106,
      "embedding_norm": 1.0
    },
    {
      "module_path": "Tool.Lcr",
      "library": "lambdapi.tool",
      "description": "This module handles operations for incremental local confluence verification by analyzing critical pairs between rewrite rules. It works with rewrite systems, substitutions, and higher-order patterns, employing unification and subterm traversal to detect joinability while avoiding variable name clashes through shifting. It is particularly used in scenarios where new rules are added incrementally to an existing system, ensuring only necessary critical pairs are checked without revalidating previously verified ones.",
      "description_length": 519,
      "index": 107,
      "embedding_norm": 0.9999999403953552
    },
    {
      "module_path": "Tool.Indexing",
      "library": "lambdapi.tool",
      "description": "This module manages indexing operations for a command search feature, supporting both plain text and HTML output formats. It provides functions to initialize an empty index, index a sign with specific rules, and dump the index for debugging or persistence. The module works directly with `Core.Sign.t` and string-based search queries, producing formatted command search results.",
      "description_length": 378,
      "index": 108,
      "embedding_norm": 0.9999999403953552
    },
    {
      "module_path": "Tool.Websearch",
      "library": "lambdapi.tool",
      "description": "Starts a web search service on the specified port, listening for incoming HTTP requests. It handles query parameters to perform searches and returns results in a structured format. This function is typically used to deploy a standalone search API endpoint.",
      "description_length": 256,
      "index": 109,
      "embedding_norm": 0.9999999403953552
    },
    {
      "module_path": "Tool.Sr",
      "library": "lambdapi.tool",
      "description": "Implements type preservation checks for formal rewriting rules. Processes `pre_rule` structures annotated with source positions, verifying their type correctness within a given signature state and converting them into fully typed rules. Used during the validation of transformation rules in a type-safe rewriting system.",
      "description_length": 320,
      "index": 110,
      "embedding_norm": 1.0
    },
    {
      "module_path": "Tool",
      "library": "lambdapi.tool",
      "description": "This module provides tools for visualizing decision trees, validating signatures with external checkers, verifying confluence in rewrite systems, indexing commands for search, running a web search service, and checking type preservation in rewriting rules. It centers around data types like `Core.Term.dtree`, `Core.Sign.t`, and `pre_rule`, offering operations for rendering graphs, executing commands, unifying terms, formatting search results, serving HTTP queries, and ensuring type correctness. You can generate DOT visualizations of decision trees, run signature checks with custom tools, verify rewrite rule confluence incrementally, index and search commands in text or HTML, expose a search API over HTTP, and validate typed rewriting rules from annotated sources.",
      "description_length": 772,
      "index": 111,
      "embedding_norm": 0.9999999403953552
    },
    {
      "module_path": "Parsing.DkBasic.WS",
      "library": "lambdapi.parsing",
      "description": "This module implements a data structure for managing a collection of `Parsing.DkBasic.ident` values with operations for adding, removing, merging, and querying elements. It supports efficient lookups, membership checks, and traversal via iterators and folds, while maintaining internal state for performance statistics. Typical use cases include symbol table management and tracking identifiers during parsing or type-checking phases in Dedukti.",
      "description_length": 445,
      "index": 112,
      "embedding_norm": 1.0
    },
    {
      "module_path": "Parsing.Parser.Lp",
      "library": "lambdapi.parsing",
      "description": "This module provides functions to parse Lambdapi syntax from various input sources, including files, strings, and input channels, producing streams of commands, terms, or search queries. It operates on input channels, strings, and file paths, returning structured data such as `Parsing.Syntax.ast`, `p_term`, `query`, and `qident`. These functions support incremental parsing of formal logic content, enabling use cases like reading proof scripts or querying structured term data from external sources.",
      "description_length": 502,
      "index": 113,
      "embedding_norm": 0.9999999403953552
    },
    {
      "module_path": "Parsing.Syntax.P",
      "library": "lambdapi.parsing",
      "description": "This module constructs `p_term` values representing syntactic elements of parsed terms, using identifiers, patterns, applications, abstractions, and wildcards. It supports building terms from paths, strings, and variables, and allows forming patterns, applying terms to other terms or wildcards, and creating abstraction rules. Concrete use cases include generating lambda expressions, pattern matches, and term transformations during parsing.",
      "description_length": 443,
      "index": 114,
      "embedding_norm": 0.9999999403953552
    },
    {
      "module_path": "Parsing.Parser.PARSER",
      "library": "lambdapi.parsing",
      "description": "This module defines the interface for parsing input into abstract syntax trees. It provides functions to parse commands from a file, a string, or an input channel, all returning a lazy stream of syntax trees. It is used to process both Lambdapi and Dedukti source code representations.",
      "description_length": 285,
      "index": 115,
      "embedding_norm": 0.9999998807907104
    },
    {
      "module_path": "Parsing.Pratt.Pratt",
      "library": "lambdapi.parsing",
      "description": "This module implements Pratt parsing for infix and prefix operators, transforming parsed terms based on operator precedence and associativity. It operates on `Parsing.Syntax.p_term` values, using a `Core.Sig_state.t` and `Core.Env.t` to resolve symbols and construct new terms during parsing. It is used to desugar operator applications in a term according to the declared operator precedences and fixities.",
      "description_length": 407,
      "index": 116,
      "embedding_norm": 0.9999999403953552
    },
    {
      "module_path": "Parsing.Parser.Dk",
      "library": "lambdapi.parsing",
      "description": "Parses Dedukti syntax from input channels, files, or strings into abstract syntax trees. Works with input streams and string-based sources, producing streams of commands lazily. Used to process Dedukti source code during compilation or interactive sessions.",
      "description_length": 257,
      "index": 117,
      "embedding_norm": 0.9999999403953552
    },
    {
      "module_path": "Parsing.Scope",
      "library": "lambdapi.parsing",
      "description": "This module processes parsed terms and patterns, resolving identifiers into bound variables or symbols within a signature state and environment. It supports operations for scoping terms, search patterns, and rewrite rules, ensuring correct handling of metavariables and symbol resolution. Concrete use cases include converting parser-level rewrite rules into core terms and validating term structure during type checking or rewriting in a proof assistant.",
      "description_length": 455,
      "index": 118,
      "embedding_norm": 0.9999999403953552
    },
    {
      "module_path": "Parsing.Syntax",
      "library": "lambdapi.parsing",
      "description": "This module organizes and manipulates the abstract syntax of logical expressions, combining core validation and traversal operations with term construction capabilities from its child module. It centers on data types like `p_term`, representing identifiers, patterns, abstractions, and applications, and supports operations such as term building, structural comparison, and normalization. With it, developers can generate lambda expressions, extract parameters from inductive definitions, or validate proof script syntax during parsing. The integration of direct APIs for syntax checking and submodules for term manipulation enables both analysis and transformation of logical structures in proof assistants.",
      "description_length": 708,
      "index": 119,
      "embedding_norm": 1.0
    },
    {
      "module_path": "Parsing.DkLexer",
      "library": "lambdapi.parsing",
      "description": "This module implements lexical analysis for Dedukti source files, converting character streams into structured tokens. It processes input using standard OCaml lexing facilities, handling identifiers, strings, comments, and other syntactic elements specific to Dedukti. Key operations include token recognition, position tracking, and error reporting during lexing.",
      "description_length": 364,
      "index": 120,
      "embedding_norm": 1.0
    },
    {
      "module_path": "Parsing.Pratt",
      "library": "lambdapi.parsing",
      "description": "This module implements Pratt parsing to resolve infix and prefix operators in `p_term` values, using `Sig_state` and `Env` to determine operator scope and structure during parsing. It transforms complex operator expressions into explicit syntactic forms based on precedence and associativity rules. Submodules handle the core parsing logic, symbol resolution, and term transformation, enabling desugaring of operator applications as they are parsed. Example uses include parsing arithmetic or logical expressions where operator fixity and precedence must be respected to produce correctly structured terms.",
      "description_length": 606,
      "index": 121,
      "embedding_norm": 1.0
    },
    {
      "module_path": "Parsing.Package",
      "library": "lambdapi.parsing",
      "description": "This module handles reading and applying package configuration data from `.pkg` files, which define a package's name and root path. It provides functions to locate configuration files relative to a given path, parse their contents, and apply the configuration. Use cases include determining module paths during package installation and resolving package roots from source or object files.",
      "description_length": 388,
      "index": 122,
      "embedding_norm": 0.9999999403953552
    },
    {
      "module_path": "Parsing.DkParser",
      "library": "lambdapi.parsing",
      "description": "Parses a sequence of tokens into a structured command representation using a specified lexical buffer. It operates on `token` values defined in `Parsing.DkTokens` and constructs abstract syntax trees of type `Syntax.p_command`. This module is used to translate raw lexical input into executable command structures in a defined grammar.",
      "description_length": 335,
      "index": 123,
      "embedding_norm": 1.0
    },
    {
      "module_path": "Parsing.DkBasic",
      "library": "lambdapi.parsing",
      "description": "This module provides core types and operations for handling identifiers and module identifiers as strings, with support for equality checks, hashing, and whitespace-sensitive manipulation through the WS submodule. It enables the creation and structured management of identifiers used in parsing and symbol resolution, particularly for variable and module names in Dedukti source files. The child module extends this functionality by offering efficient collection operations\u2014such as insertion, membership testing, and traversal\u2014over sets of identifiers, supporting use cases like symbol table construction and static analysis. Together, they form a foundation for managing lexical entities with performance-conscious data structures and utility functions.",
      "description_length": 754,
      "index": 124,
      "embedding_norm": 0.9999999403953552
    },
    {
      "module_path": "Parsing.Pretty",
      "library": "lambdapi.parsing",
      "description": "This module provides pretty-printing functions for parser-level abstract syntax trees, handling elements like identifiers, terms, rules, and inductive definitions. It operates on structured types such as `p_ident`, `p_term`, and `p_rule`, using a keyword table to manage language-specific keywords and enforce correct precedence during formatting. These utilities are used to transform Dedukti parser outputs into human-readable Lambdapi syntax, leveraging `Lplib.Base.pp` for consistent textual representation of complex syntax nodes.",
      "description_length": 535,
      "index": 125,
      "embedding_norm": 1.0
    },
    {
      "module_path": "Parsing.LpLexer",
      "library": "lambdapi.parsing",
      "description": "This module implements a Unicode-aware lexer for tokenizing LP input streams, using SEDLex-generated character classification tables and finite automata transitions. It processes UTF-8 encoded text into structured tokens (keywords, identifiers, literals) through integer-based state transitions and partitioned character code analysis. Key use cases include parsing LP models with complex identifier escaping rules, handling numeric/string literals, and maintaining lexing state with positional error reporting.",
      "description_length": 511,
      "index": 126,
      "embedding_norm": 1.0
    },
    {
      "module_path": "Parsing.SearchQuerySyntax",
      "library": "lambdapi.parsing",
      "description": "This module defines a structured query language for parsing and filtering symbolic data, supporting operations like intersection, union, and path-based filtering. It works with abstract syntax trees representing search queries, including named entities, term patterns, and constraints on structure or location. Concrete use cases include querying codebases for specific syntactic patterns, filtering results by file path, and composing complex search expressions from simpler components.",
      "description_length": 487,
      "index": 127,
      "embedding_norm": 0.9999999403953552
    },
    {
      "module_path": "Parsing.DkRule",
      "library": "lambdapi.parsing",
      "description": "Decomposes and reconstructs parser-level terms into function-application spines, handling positional metadata for arguments. Operates on `p_term` and `p_dk_rule` structures, which represent terms and rewrite rules with source positions. Used to transform dk-style rules into lp-style rules while preserving argument positions.",
      "description_length": 326,
      "index": 128,
      "embedding_norm": 1.0
    },
    {
      "module_path": "Parsing.DkTokens",
      "library": "lambdapi.parsing",
      "description": "This module defines token types and location tracking for parsing Dedukti source files. It includes specific tokens for keywords, identifiers, operators, and structural symbols used in Dedukti syntax. Concrete use cases include lexing input files into structured tokens and tracking source positions for error reporting during parsing.",
      "description_length": 335,
      "index": 129,
      "embedding_norm": 0.9999999403953552
    },
    {
      "module_path": "Parsing.LpParser",
      "library": "lambdapi.parsing",
      "description": "This module provides functions to parse individual terms, search queries, qualified identifiers, and commands from lexing buffers using a specified token stream. It operates on lexbuf inputs and produces structured syntax trees for logical terms, queries, and commands. Concrete use cases include parsing user input for theorem proving commands or query expressions in a logic programming environment.",
      "description_length": 401,
      "index": 130,
      "embedding_norm": 1.0
    },
    {
      "module_path": "Parsing.Parser",
      "library": "lambdapi.parsing",
      "description": "This module parses Lambdapi and Dedukti syntax from files, strings, or input channels into abstract syntax trees, commands, or term streams. It supports both direct parsing and incremental processing, producing structured data like `ast`, `p_term`, and `query`, with utilities for identifier and path conversion. The Lp submodule handles Lambdapi-specific parsing for commands, terms, and search queries, while the Dk submodule focuses on Dedukti syntax, returning lazy streams of syntax trees for compilation or interactive use. Examples include loading proof scripts, evaluating input expressions, or streaming terms from external sources.",
      "description_length": 641,
      "index": 131,
      "embedding_norm": 1.0
    },
    {
      "module_path": "Parsing",
      "library": "lambdapi.parsing",
      "description": "This module processes input streams into structured logical representations, handling lexical analysis, parsing, and term manipulation for languages like Dedukti and Lambdapi. It centers on data types such as `p_term`, `p_command`, and `token`, with operations for identifier resolution, operator precedence parsing, term normalization, and pretty-printing. Developers can use it to parse and validate proof scripts, transform rewrite rules, query symbolic data, and manage package configurations, all while maintaining source position tracking for error reporting and term reconstruction. Specific applications include converting arithmetic expressions into core terms, extracting inductive definitions, and streaming syntax trees from files for theorem proving.",
      "description_length": 763,
      "index": 132,
      "embedding_norm": 0.9999998807907104
    }
  ],
  "filtering": {
    "total_modules_in_package": 136,
    "meaningful_modules": 133,
    "filtered_empty_modules": 3,
    "retention_rate": 0.9779411764705882
  },
  "statistics": {
    "max_description_length": 857,
    "min_description_length": 256,
    "avg_description_length": 507.57142857142856,
    "embedding_file_size_mb": 0.4836091995239258
  }
}