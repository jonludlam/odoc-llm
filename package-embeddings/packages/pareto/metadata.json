{
  "package": "pareto",
  "embedding_model": "BAAI/bge-base-en-v1.5",
  "embedding_dimension": 1024,
  "total_modules": 39,
  "creation_timestamp": "2025-06-18T16:40:42.790936",
  "modules": [
    {
      "module_path": "Sample.Correlation.Auto",
      "description": "Calculates the autocorrelation of a float array using the Pearson correlation coefficient, comparing the array with its shifted versions. It processes sequences of numerical data to identify patterns that repeat at different offsets. This is useful for analyzing time series data to detect periodicity or trends.",
      "description_length": 312,
      "index": 0,
      "embedding_norm": 1.0
    },
    {
      "module_path": "Distributions.Categorical.Make",
      "description": "Compares two instances of type t using a total ordering, returning -1, 0, or 1 based on their relative values. It operates on the abstract type t, which represents keys in a structured format. This function is used to sort key-based data structures or determine precedence in ordered collections.",
      "description_length": 296,
      "index": 1,
      "embedding_norm": 0.9999999403953552
    },
    {
      "module_path": "Tests.T",
      "description": "Calculates statistical significance for one-sample and two-sample t-tests, including independent and paired comparisons, using specified means and alternative hypotheses. Operates on float arrays representing sample data to compute test results. Used to validate assumptions about population means in experimental data analysis.",
      "description_length": 328,
      "index": 2,
      "embedding_norm": 0.9999999403953552
    },
    {
      "module_path": "Tests.ChiSquared",
      "description": "Calculates chi-squared statistics for goodness of fit and independence tests using observed and expected frequency arrays. It returns test results including p-values and chi-squared scores. Used to validate distribution assumptions and assess relationships between categorical variables.",
      "description_length": 287,
      "index": 3,
      "embedding_norm": 1.0
    },
    {
      "module_path": "Tests.KolmogorovSmirnov",
      "description": "Calculates the Kolmogorov-Smirnov statistic and p-value for comparing an observed dataset against a specified cumulative distribution or between two datasets. Operates on float arrays and uses a provided cumulative probability function for distribution comparison. Used to validate if a sample follows a theoretical distribution or if two samples originate from the same underlying distribution.",
      "description_length": 395,
      "index": 4,
      "embedding_norm": 1.0
    },
    {
      "module_path": "Tests.MannWhitneyU",
      "description": "Calculates the Mann-Whitney U statistic to compare medians of two independent arrays, supporting one- or two-sided alternatives and continuity correction. It handles numeric or comparable data types and returns a structured result with test statistics and p-values. Used to assess if differences in distributions between two groups are statistically significant.",
      "description_length": 362,
      "index": 5,
      "embedding_norm": 1.0
    },
    {
      "module_path": "Tests.WilcoxonT",
      "description": "Performs Wilcoxon signed-rank tests on one or two paired samples to assess median equality, incorporating optional shift values and correction factors. Operates on float arrays representing sample data and returns statistical test results. Used to compare pre- and post-intervention measurements or matched pairs in experimental studies.",
      "description_length": 337,
      "index": 6,
      "embedding_norm": 1.0
    },
    {
      "module_path": "Tests.Sign",
      "description": "Performs statistical hypothesis testing using the sign test for a single sample and the paired sign test for two related samples. Accepts float arrays representing sample data and returns test results based on specified alternatives and shift values. Used to assess whether a sample's median differs from a reference value or whether two related samples have equivalent medians.",
      "description_length": 378,
      "index": 7,
      "embedding_norm": 1.0
    },
    {
      "module_path": "Tests.Multiple",
      "description": "Adjusts observed P-values for multiple comparisons using specified methods such as Bonferroni, Holm, or Benjamini-Hochberg. It processes arrays of floating-point numbers and applies statistical corrections to control error rates. This is used in statistical analysis to refine significance thresholds when testing multiple hypotheses.",
      "description_length": 334,
      "index": 8,
      "embedding_norm": 1.0
    },
    {
      "module_path": "Resampling.Bootstrap",
      "description": "Provides bias-corrected and accelerated bootstrap estimation with functions to compute point estimates, confidence intervals, and associated confidence levels. Operates on float arrays and functions that map float arrays to a single float value. Used to assess statistical uncertainty in estimators like means or regression coefficients through iterative resampling.",
      "description_length": 366,
      "index": 9,
      "embedding_norm": 1.0
    },
    {
      "module_path": "Sample.Quantile",
      "description": "Estimates quantiles and interquantile ranges using Hazen's definition with linear interpolation of the empirical cumulative distribution function. Operates on arrays of floats, applying a continuous parameter configuration to adjust estimation behavior. Used for statistical analysis requiring median-unbiased quantile estimates in scenarios like data normalization or distribution comparison.",
      "description_length": 393,
      "index": 10,
      "embedding_norm": 0.9999999403953552
    },
    {
      "module_path": "Sample.KDE",
      "description": "Estimates probability density functions using a kernel density estimator with configurable kernel and bandwidth, where bandwidth defaults to a modified Silverman's rule. It operates on float arrays, producing paired arrays of sample points and corresponding density estimates. Used for visualizing data distributions and identifying underlying patterns in numerical datasets.",
      "description_length": 375,
      "index": 11,
      "embedding_norm": 1.0
    },
    {
      "module_path": "Sample.Correlation",
      "description": "Calculates autocorrelation for float arrays by comparing each element with shifted versions, revealing repeating patterns in sequential data. It uses the Pearson correlation coefficient to quantify similarity across offsets. This enables analysis of time series for periodicity, trends, or structural similarities. For example, it can detect seasonal patterns in financial data or rhythmic structures in sensor readings.",
      "description_length": 420,
      "index": 12,
      "embedding_norm": 1.0
    },
    {
      "module_path": "Sample.Summary",
      "description": "Tracks running statistics for a stream of floating-point numbers, supporting addition, combination, and computation of mean, variance, standard deviation, skewness, and kurtosis. Maintains internal state to calculate max, min, and size without storing all values. Efficient for real-time analysis of large or continuous data sources.",
      "description_length": 333,
      "index": 13,
      "embedding_norm": 0.9999999403953552
    },
    {
      "module_path": "Distributions.Features",
      "description": "Calculates statistical measures including mean, variance, skewness, and kurtosis for a given dataset. Operates on a generic numeric type `elt` and a container type `t` representing the data. Used to analyze distribution properties in numerical data processing pipelines.",
      "description_length": 270,
      "index": 14,
      "embedding_norm": 0.9999999403953552
    },
    {
      "module_path": "Distributions.Normal",
      "description": "Generates random samples, computes probability densities, cumulative probabilities, and quantiles for floating-point values using a normal distribution. Calculates statistical properties like mean, variance, skewness, and kurtosis for a given distribution. Constructs distributions from parameters, data, or uses a standard normal distribution for quick initialization.",
      "description_length": 369,
      "index": 15,
      "embedding_norm": 0.9999999403953552
    },
    {
      "module_path": "Distributions.LogNormal",
      "description": "Provides methods to sample from and analyze log-normal distributions, compute probability densities, cumulative probabilities, and statistical moments. Operates on float values and distribution parameters defined by a mean and standard deviation. Used for generating random data, estimating parameters from samples, and calculating probabilistic metrics in statistical modeling.",
      "description_length": 378,
      "index": 16,
      "embedding_norm": 1.0
    },
    {
      "module_path": "Distributions.Uniform",
      "description": "Generates random samples and computes statistical properties of a uniform distribution over a specified interval. Calculates probability density, cumulative probability, and quantiles for floating-point values. Estimates parameters from data and provides measures like mean, variance, skewness, and kurtosis.",
      "description_length": 308,
      "index": 17,
      "embedding_norm": 1.0
    },
    {
      "module_path": "Distributions.Exponential",
      "description": "Generates and analyzes samples from an exponential distribution, computing density, cumulative probability, and quantiles for floating-point values. Supports parameter estimation from data and calculates statistical properties like mean, variance, skewness, and kurtosis. Used for modeling time intervals between events in processes with constant failure rates.",
      "description_length": 361,
      "index": 18,
      "embedding_norm": 1.0
    },
    {
      "module_path": "Distributions.ChiSquared",
      "description": "Generates and analyzes chi-squared distributed data using degrees of freedom, providing methods to sample values, calculate probabilities, and derive statistical properties. It computes density, cumulative probability, and quantiles for specific values, and supports parameter estimation from data. Used for statistical hypothesis testing and modeling sums of squared normal variables.",
      "description_length": 385,
      "index": 19,
      "embedding_norm": 0.9999999403953552
    },
    {
      "module_path": "Distributions.F",
      "description": "Provides functions to sample from and compute statistical properties of the Fisher-Snedecor distribution, including density, cumulative probability, and quantiles. Operates on floating-point values and distributions defined by degrees of freedom. Used for generating random variates in statistical simulations and estimating parameters from sample data.",
      "description_length": 353,
      "index": 20,
      "embedding_norm": 1.0
    },
    {
      "module_path": "Distributions.T",
      "description": "Generates samples and computes statistical properties of the Student's t-distribution, including density, cumulative probability, and quantiles. Operates on floating-point values and distributions defined by degrees of freedom. Estimates parameters from data using the method of moments and calculates summary statistics like mean and variance.",
      "description_length": 344,
      "index": 21,
      "embedding_norm": 1.0
    },
    {
      "module_path": "Distributions.Gamma",
      "description": "Provides functions to sample from and compute statistical properties of a gamma distribution, including density, cumulative probability, quantiles, and moments. Operates on float values and a distribution parameter type encapsulating shape and scale. Used for generating random data, statistical analysis, and parameter estimation from empirical data.",
      "description_length": 351,
      "index": 22,
      "embedding_norm": 1.0
    },
    {
      "module_path": "Distributions.Cauchy",
      "description": "Provides functions to sample from and compute statistical properties of the Cauchy-Lorentz distribution, including density, cumulative probability, and quantiles. Operates on float values and a distribution structure defined by location and scale parameters. Used for generating random samples in physics simulations or calculating probabilities in robust statistical models.",
      "description_length": 375,
      "index": 23,
      "embedding_norm": 1.0
    },
    {
      "module_path": "Distributions.Beta",
      "description": "Provides functions to sample from and analyze beta distributions, compute probability density and cumulative functions, and calculate statistical moments. Operates on float values and distribution parameters represented as a record type. Used for statistical modeling, hypothesis testing, and generating random variates in probabilistic simulations.",
      "description_length": 349,
      "index": 24,
      "embedding_norm": 1.0
    },
    {
      "module_path": "Distributions.Logistic",
      "description": "Provides functions to sample from and compute statistical properties of a logistic distribution, including density, cumulative probability, quantiles, and moments. Operates on float values and a distribution type encapsulating location and scale parameters. Used for generating random data, calculating probabilities, and estimating parameters from observed data.",
      "description_length": 363,
      "index": 25,
      "embedding_norm": 1.0
    },
    {
      "module_path": "Distributions.Poisson",
      "description": "Generates and analyzes Poisson-distributed random variables using methods like sampling, cumulative probability calculation, and parameter estimation. Operates on integer values and a distribution structure defined by a rate parameter. Computes statistical properties such as mean, variance, and skewness, and fits distributions to observed data.",
      "description_length": 346,
      "index": 26,
      "embedding_norm": 1.0
    },
    {
      "module_path": "Distributions.Bernoulli",
      "description": "Generates and analyzes Bernoulli-distributed random variables using parameters like success probability p. Computes probability mass, cumulative probabilities, and statistical moments such as mean and variance. Samples from the distribution or estimates parameters from observed data.",
      "description_length": 284,
      "index": 27,
      "embedding_norm": 1.0
    },
    {
      "module_path": "Distributions.Binomial",
      "description": "Computes probability mass, cumulative probability, and statistical moments for binomial distributions. Operates on integer values representing successes in a fixed number of Bernoulli trials. Used for simulating random outcomes in experiments with binary results, such as coin flips or success/failure tests.",
      "description_length": 308,
      "index": 28,
      "embedding_norm": 1.0
    },
    {
      "module_path": "Distributions.Geometric",
      "description": "Provides functions to compute probability mass, cumulative probability, and statistical moments for the geometric distribution. Operates on integer values representing the number of failures before a success, and supports sampling from the distribution. Estimates parameters using method of moments and calculates mean, variance, skewness, and kurtosis.",
      "description_length": 353,
      "index": 29,
      "embedding_norm": 0.9999999403953552
    },
    {
      "module_path": "Distributions.Hypergeometric",
      "description": "Calculates probability mass and cumulative probabilities for hypergeometric events, computes statistical moments like mean and variance, and generates random samples from the distribution. Operates on integer values representing counts of successes and failures in a population. Used for modeling scenarios like drawing cards from a deck or analyzing genetic traits in a sample.",
      "description_length": 378,
      "index": 30,
      "embedding_norm": 0.9999999403953552
    },
    {
      "module_path": "Distributions.NegativeBinomial",
      "description": "Provides functions to compute probability mass, cumulative probability, and statistical moments for the negative binomial distribution. Operates on integer-valued random variables and floating-point parameters representing success probabilities and failure counts. Samples from the distribution, estimates parameters from data, and calculates mean, variance, skewness, and kurtosis.",
      "description_length": 382,
      "index": 31,
      "embedding_norm": 1.0
    },
    {
      "module_path": "Distributions.Categorical",
      "description": "Provides functions to sample from and evaluate categorical distributions, including probability mass, cumulative probability, and log probability calculations. Works with a type `elt` representing categorical values and a type `t` representing the distribution structure. Used to generate random samples, compute statistical properties, and estimate distributions from observed data.",
      "description_length": 383,
      "index": 32,
      "embedding_norm": 0.9999999403953552
    },
    {
      "module_path": "pareto",
      "description": "Provides functions to compute and manipulate Pareto frontiers, including dominance checks, frontier extraction, and point filtering. Operates on lists of tuples representing multi-dimensional data points. Used to identify optimal solutions in multi-objective optimization scenarios.",
      "description_length": 282,
      "index": 33,
      "embedding_norm": 1.0
    },
    {
      "module_path": "Tests",
      "description": "Provides statistical hypothesis testing across multiple methods, including t-tests, chi-squared, Kolmogorov-Smirnov, Mann-Whitney U, Wilcoxon, sign tests, and p-value corrections. Operates on float arrays and cumulative distribution functions to compute test statistics, p-values, and adjusted significance levels. Supports one- and two-sample comparisons, goodness-of-fit, independence, and distributional assumptions. Examples include validating population means, assessing categorical variable relationships, and correcting for multiple hypothesis testing.",
      "description_length": 559,
      "index": 34,
      "embedding_norm": 1.0
    },
    {
      "module_path": "Resampling",
      "description": "Calculates bootstrap estimates, confidence intervals, and confidence levels for statistical measures derived from float arrays. Supports bias correction and acceleration to refine interval accuracy, with operations tailored for functions that aggregate arrays into single float values. Enables assessment of estimator stability, such as determining the confidence interval for a regression coefficient or sample mean. Processes data through repeated resampling to quantify uncertainty in statistical results.",
      "description_length": 508,
      "index": 35,
      "embedding_norm": 1.0
    },
    {
      "module_path": "Sample",
      "description": "Calculates quantiles, density estimates, autocorrelation, and running statistics from float arrays, offering tools for distribution analysis, pattern detection, and real-time data summarization. It handles continuous data through kernel density estimation, quantile interpolation, and autocorrelation computation, while maintaining efficient state for streaming inputs. Users can estimate median-unbiased quantiles, visualize density functions, detect periodicity in time series, and track summary statistics on the fly. Examples include normalizing data with interquantile ranges, identifying distribution modes via density plots, and analyzing sensor data for recurring patterns.",
      "description_length": 681,
      "index": 36,
      "embedding_norm": 1.0
    },
    {
      "module_path": "Base",
      "description": "Performs cumulative calculations, binary searches on sorted arrays, and reorders elements based on index permutations. Handles arrays of arbitrary types and integer ranges, with support for shuffling and sampling. Useful for data preprocessing tasks like transforming data sequences, locating elements efficiently, and generating randomized subsets.",
      "description_length": 349,
      "index": 37,
      "embedding_norm": 1.0
    },
    {
      "module_path": "Distributions",
      "description": "Provides functions to sample from a distribution, compute cumulative and point probabilities, and calculate log probabilities. Operates on a generic element type `elt` and a distribution type `t`. Used for statistical modeling, hypothesis testing, and generating random data for simulations.",
      "description_length": 291,
      "index": 38,
      "embedding_norm": 1.0
    }
  ],
  "filtering": {
    "total_modules_in_package": 40,
    "meaningful_modules": 39,
    "filtered_empty_modules": 1,
    "retention_rate": 0.975
  },
  "statistics": {
    "max_description_length": 681,
    "min_description_length": 270,
    "avg_description_length": 364.7692307692308,
    "embedding_file_size_mb": 0.14208698272705078
  }
}