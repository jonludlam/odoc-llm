{
  "package": "llama-cpp-ocaml",
  "embedding_model": "BAAI/bge-base-en-v1.5",
  "embedding_dimension": 1024,
  "total_modules": 1,
  "creation_timestamp": "2025-06-18T16:26:27.217760",
  "modules": [
    {
      "module_path": "llama-cpp-ocaml",
      "description": "Provides functions to load and execute large language models, including inference and context management. Works with model files in the format supported by llama.cpp, such as GGUF and GGML. Used to run text generation tasks with minimal resource overhead.",
      "description_length": 255,
      "index": 0,
      "embedding_norm": 1.0
    }
  ],
  "filtering": {
    "total_modules_in_package": 1,
    "meaningful_modules": 1,
    "filtered_empty_modules": 0,
    "retention_rate": 1.0
  },
  "statistics": {
    "max_description_length": 255,
    "min_description_length": 255,
    "avg_description_length": 255.0,
    "embedding_file_size_mb": 0.0040740966796875
  }
}