{
  "package": "talaria-bibtex",
  "embedding_model": "BAAI/bge-base-en-v1.5",
  "embedding_dimension": 1024,
  "total_modules": 9,
  "creation_timestamp": "2025-06-18T16:32:03.142987",
  "modules": [
    {
      "module_path": "Bibtex.Fields.StrSet",
      "description": "The module provides set operations like union, intersection, and difference, along with querying and transformation functions, operating on ordered collections of elements such as strings and lists. It supports ordered traversal, predicate-based searches, and conversions between sets and sequences, enabling efficient manipulation of structured data. Use cases include managing string-based datasets requiring sorted access or reverse iteration, as well as implementing algorithms reliant on set relationships and element filtering.",
      "description_length": 533,
      "index": 0,
      "embedding_norm": 0.9999999403953552
    },
    {
      "module_path": "Bibtex.Fields.Database",
      "description": "This module provides operations for creating, modifying, and querying ordered maps, including adding, removing, and merging key-value pairs, as well as iterating over subsets or converting between maps and sequences. It works with ordered key-value structures, particularly string-based maps, and supports traversal in increasing or decreasing order, filtering, and transformation via folding. Use cases include efficient data aggregation, dynamic map construction from streams, and predicate-driven data extraction.",
      "description_length": 516,
      "index": 1,
      "embedding_norm": 0.9999999403953552
    },
    {
      "module_path": "Bibtex.Fields",
      "description": "combines set and map operations for structured data manipulation, offering ordered collections of strings and key-value pairs with efficient querying, transformation, and traversal. It supports set unions, intersections, and map merges, along with predicate-based filtering and sequence conversions. Users can manage sorted datasets, build dynamic maps from streams, or extract subsets based on conditions. Examples include merging bibliographic entries, filtering fields by type, or generating ordered summaries from unstructured data.",
      "description_length": 536,
      "index": 2,
      "embedding_norm": 0.9999999403953552
    },
    {
      "module_path": "Bibtex.Field_parsers",
      "description": "Parses structured text to extract tags, paths, page information, and names from a lexing buffer using a provided token reader. Operates on lexing buffers and returns lists or custom page data structures. Used to process configuration files or markup formats where specific fields need to be extracted and categorized.",
      "description_length": 317,
      "index": 3,
      "embedding_norm": 0.9999999403953552
    },
    {
      "module_path": "Bibtex.Field_lexers",
      "description": "Processes and tokenizes structured text inputs such as field pages, names, tags, and file paths using predefined lexical tables. Operates on `Lexing.lexbuf` and returns `Field_parsers.token` for parsing structured data. Supports recursive scanning for complex patterns in fields, tags, and hierarchical paths.",
      "description_length": 309,
      "index": 4,
      "embedding_norm": 1.0
    },
    {
      "module_path": "Bibtex.Field_types",
      "description": "Provides functions to manage publication statuses, including checking validity, converting between representations, and extracting metadata. Works with custom types for pages, names, kinds, and states. Used to validate and transform data during document processing workflows.",
      "description_length": 275,
      "index": 5,
      "embedding_norm": 0.9999999403953552
    },
    {
      "module_path": "Bibtex.Lexer",
      "description": "Handles lexical analysis for Bibtex input, processing character streams into tokens. Operates on lexing buffers and predefined lexing tables to parse structured data. Used to convert raw text into a sequence of recognized tokens for further parsing.",
      "description_length": 249,
      "index": 6,
      "embedding_norm": 1.0
    },
    {
      "module_path": "talaria-bibtex",
      "description": "Provides functions to parse and generate BibTeX entries, including reading from and writing to files, extracting fields, and validating entry types. Operates on strings, lists, and custom record types representing bibliography entries. Used to process academic references in research workflows and generate formatted citations.",
      "description_length": 327,
      "index": 7,
      "embedding_norm": 1.0
    },
    {
      "module_path": "Bibtex",
      "description": "combines set and map operations with text parsing and tokenization to manage structured data, offering ordered collections, key-value mappings, and field extraction from lexed inputs. It supports merging, filtering, and transforming data, along with parsing tags, names, and page information from text streams. Users can validate publication metadata, extract fields from configuration files, and generate ordered summaries from unstructured content. Operations include set unions, map merges, recursive token scanning, and structured data conversion.",
      "description_length": 551,
      "index": 8,
      "embedding_norm": 1.0
    }
  ],
  "filtering": {
    "total_modules_in_package": 10,
    "meaningful_modules": 9,
    "filtered_empty_modules": 1,
    "retention_rate": 0.9
  },
  "statistics": {
    "max_description_length": 551,
    "min_description_length": 249,
    "avg_description_length": 401.44444444444446,
    "embedding_file_size_mb": 0.033123016357421875
  }
}