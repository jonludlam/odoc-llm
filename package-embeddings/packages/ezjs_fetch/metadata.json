{
  "package": "ezjs_fetch",
  "embedding_model": "Qwen/Qwen3-Embedding-0.6B",
  "embedding_dimension": 1024,
  "total_modules": 3,
  "creation_timestamp": "2025-07-15T23:07:12.413432",
  "modules": [
    {
      "module_path": "Ezjs_fetch_lwt",
      "library": "ezjs_fetch.lwt",
      "description": "This module enables asynchronous HTTP requests with customizable headers, methods, and bodies, including support for processing responses as streams, strings, or binary data. It operates on HTTP request/response pairs, providing utilities to translate bodies into formats like blobs, form data, and text",
      "description_length": 303,
      "index": 0,
      "embedding_norm": 0.9999999403953552
    },
    {
      "module_path": "Ezjs_fetch.Stream",
      "library": "ezjs_fetch",
      "description": "This module implements streaming data processing with support for reading from and writing to streams using custom transformers and strategies. It defines types for readable, writable, and transform streams, along with operations to construct and manipulate them. Concrete use cases include processing HTTP responses in chunks, implementing custom stream encodings, and handling backpressure in data pipelines.",
      "description_length": 410,
      "index": 1,
      "embedding_norm": 1.0
    },
    {
      "module_path": "Ezjs_fetch",
      "library": "ezjs_fetch",
      "description": "This module provides tools for building and handling HTTP requests and responses using the Fetch API in OCaml, supporting headers, bodies, and response conversion through types like `request_body` and `response_js`. It enables streaming data processing through submodules that implement readable, writable, and transform streams, allowing operations like chunked HTTP response handling and custom stream encodings. You can send requests with custom headers and body content, then process the response asynchronously as text, blob, or array buffer. The streaming submodule supports constructing and manipulating streams with custom transformers and strategies, enabling efficient data pipeline implementations with backpressure handling.",
      "description_length": 736,
      "index": 2,
      "embedding_norm": 1.0
    }
  ],
  "filtering": {
    "total_modules_in_package": 37,
    "meaningful_modules": 3,
    "filtered_empty_modules": 34,
    "retention_rate": 0.08108108108108109
  },
  "statistics": {
    "max_description_length": 736,
    "min_description_length": 303,
    "avg_description_length": 483.0,
    "embedding_file_size_mb": 0.01131439208984375
  }
}