{
  "package": "ocamldiff",
  "embedding_model": "Qwen/Qwen3-Embedding-0.6B",
  "embedding_dimension": 1024,
  "total_modules": 4,
  "creation_timestamp": "2025-07-15T23:04:55.710697",
  "modules": [
    {
      "module_path": "Odiff_types",
      "library": "ocamldiff",
      "description": "This module defines types for representing and manipulating differences between two files. It includes variants for additions, deletions, and changes, each capturing line indices and associated text. These types are used to model the output of a diff operation, enabling precise tracking of modifications between file versions.",
      "description_length": 327,
      "index": 0,
      "embedding_norm": 0.9999999403953552
    },
    {
      "module_path": "Odiff",
      "library": "ocamldiff",
      "description": "This module computes and manipulates differences between files or strings, producing structured output in the form of `diff` values that represent additions, deletions, and changes with line numbers. It supports parsing diff output from strings, files, or channels, and can print diffs in a human-readable format with optional line number offsets. Concrete use cases include comparing configuration files, tracking changes in text documents, or generating patch-like output for version control systems.",
      "description_length": 502,
      "index": 1,
      "embedding_norm": 1.0
    },
    {
      "module_path": "Odiff_parser",
      "library": "ocamldiff",
      "description": "Parses diff output into structured data by converting lexed tokens into a list of changes. It handles tokens representing line indices, additions, deletions, and separators, mapping them to a typed representation of file differences. This module is used to process Git-style diff text into a format suitable for programmatic analysis or rendering.",
      "description_length": 347,
      "index": 2,
      "embedding_norm": 1.0
    },
    {
      "module_path": "Odiff_lexer",
      "library": "ocamldiff",
      "description": "This module implements a lexer for parsing input into tokens, primarily handling character streams using OCaml's `Lexing.lexbuf`. It includes entry points for lexing operations and maintains internal state for line tracking. Concrete use cases include tokenizing source code or structured text input for further parsing.",
      "description_length": 320,
      "index": 3,
      "embedding_norm": 1.0
    }
  ],
  "filtering": {
    "total_modules_in_package": 4,
    "meaningful_modules": 4,
    "filtered_empty_modules": 0,
    "retention_rate": 1.0
  },
  "statistics": {
    "max_description_length": 502,
    "min_description_length": 320,
    "avg_description_length": 374.0,
    "embedding_file_size_mb": 0.014955520629882812
  }
}