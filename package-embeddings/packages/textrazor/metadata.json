{
  "package": "textrazor",
  "embedding_model": "Qwen/Qwen3-Embedding-0.6B",
  "embedding_dimension": 1024,
  "total_modules": 14,
  "creation_timestamp": "2025-07-15T23:07:37.899503",
  "modules": [
    {
      "module_path": "Textrazor.Analysis.Options",
      "library": "textrazor",
      "description": "This module defines configuration options for text analysis, including classifiers, extractors, and cleanup modes. It works with strings, lists, and custom types to specify analysis behavior. Use it to customize API requests for text processing tasks like entity extraction or classification.",
      "description_length": 292,
      "index": 0,
      "embedding_norm": 1.0
    },
    {
      "module_path": "Textrazor.Word",
      "library": "textrazor",
      "description": "This module defines a record type representing detailed linguistic information about a word, including its position in text, part of speech, lemma, and stemmed form. It provides a function to construct such records from JSON data, typically used when parsing API responses containing analyzed text. Concrete use cases include natural language processing tasks like syntactic analysis, token normalization, and information extraction from unstructured text.",
      "description_length": 456,
      "index": 1,
      "embedding_norm": 1.0
    },
    {
      "module_path": "Textrazor.Sentence",
      "library": "textrazor",
      "description": "This module represents sentences in a structured format, with each sentence containing a position index and a list of words. It provides functionality to parse sentence data from JSON using `of_yojson`, organizing words into a list tied to their original position. It is used to analyze and process textual content by breaking it into discrete sentences and their constituent words.",
      "description_length": 382,
      "index": 2,
      "embedding_norm": 1.0
    },
    {
      "module_path": "Textrazor.Category",
      "library": "textrazor",
      "description": "This module defines a category type with fields for classifier ID, category ID, label, and confidence score. It provides a function to parse category data from JSON using Yojson. This module is used to represent and process text classification results from the Textrazor API.",
      "description_length": 275,
      "index": 3,
      "embedding_norm": 1.0
    },
    {
      "module_path": "Textrazor.Relation",
      "library": "textrazor",
      "description": "This module handles the parsing and representation of syntactic relations in text analysis. It processes JSON data into structured types that capture relationships between words, including their positions. Concrete use cases include extracting grammatical dependencies and analyzing sentence structure from natural language input.",
      "description_length": 330,
      "index": 4,
      "embedding_norm": 1.0
    },
    {
      "module_path": "Textrazor.Entity",
      "library": "textrazor",
      "description": "This module defines a structured representation of entities extracted from text, including identifiers, type information, and links to external knowledge bases. It provides functions to parse entity data from JSON and construct URIs for Wikidata, Freebase, and Wikipedia entries. Use this module to analyze and link recognized entities to their corresponding knowledge graph resources.",
      "description_length": 385,
      "index": 5,
      "embedding_norm": 0.9999999403953552
    },
    {
      "module_path": "Textrazor.Analysis",
      "library": "textrazor",
      "description": "This module analyzes text using the TextRazor API, extracting structured data such as entities, topics, and relations from raw or cleaned input. It supports configuration through options that control extractors, classifiers, and text cleanup, allowing precise tailoring of analysis output. The configuration submodule provides data types and functions to define analysis behavior, such as selecting specific extractors or setting cleanup modes. Use this module to perform semantic analysis, content tagging, or information extraction by combining direct analysis functions with custom configuration settings.",
      "description_length": 608,
      "index": 6,
      "embedding_norm": 1.0
    },
    {
      "module_path": "Textrazor.Entailment",
      "library": "textrazor",
      "description": "This module defines a type `t` representing entailment data with numeric scores, word lists, and positions. It includes a function `of_yojson` to parse JSON into this structure. Use this module to extract and process entailment relationships from text analysis results, such as identifying inferred terms and their relevance scores.",
      "description_length": 332,
      "index": 7,
      "embedding_norm": 0.9999999403953552
    },
    {
      "module_path": "Textrazor.Account",
      "library": "textrazor",
      "description": "Handles account information retrieval from the Textrazor API, including usage statistics and plan details. It works with JSON data through `Yojson.Safe.t` and maps it to an account record type. This module is used to check current API usage limits and billing plan information for a Textrazor account.",
      "description_length": 301,
      "index": 8,
      "embedding_norm": 1.0
    },
    {
      "module_path": "Textrazor.Phrase",
      "library": "textrazor",
      "description": "Handles parsing and structuring phrase data from JSON, specifically extracting phrase identifiers and word positions. Works with JSON objects and constructs phrase records containing integer IDs and lists of word indices. Useful for processing natural language responses where phrases are identified with their positions in text.",
      "description_length": 329,
      "index": 9,
      "embedding_norm": 0.9999999403953552
    },
    {
      "module_path": "Textrazor.Property",
      "library": "textrazor",
      "description": "This module defines a data structure representing a property with identifiers and positional data. It includes functions for parsing JSON input into a structured format with specific field mappings. The module is used to extract and organize property information from textual analysis results.",
      "description_length": 293,
      "index": 10,
      "embedding_norm": 1.0
    },
    {
      "module_path": "Textrazor.Client",
      "library": "textrazor",
      "description": "This module handles HTTP communication with the Textrazor API, providing functions to create a client configuration and send GET or POST requests. It works with strings for API paths, client configurations containing API keys and endpoint settings, and returns JSON responses wrapped in result types. Concrete use cases include sending text analysis requests to the API and retrieving structured data like entities or topics from the response.",
      "description_length": 443,
      "index": 11,
      "embedding_norm": 1.0
    },
    {
      "module_path": "Textrazor.Topic",
      "library": "textrazor",
      "description": "This module defines a data structure for representing topics with identifiers, labels, confidence scores, and optional links to Wikidata and Wikipedia. It provides functions to parse topic data from JSON and construct URIs for external references. Use this module to extract and work with semantic topics from text analysis results, such as identifying entities and their contextual relevance in documents.",
      "description_length": 406,
      "index": 12,
      "embedding_norm": 0.9999999403953552
    },
    {
      "module_path": "Textrazor",
      "library": "textrazor",
      "description": "This module analyzes text through the Textrazor API, extracting structured linguistic data such as words, sentences, entities, topics, and syntactic relations. It processes JSON responses into typed records for parts of speech, lemmas, classifications, entailments, and knowledge graph links, enabling tasks like semantic analysis, information extraction, and content tagging. Users can configure analysis behavior, send API requests, and retrieve structured results such as entity mentions, sentence breakdowns, or topic inferences. Example uses include normalizing tokens, identifying grammatical dependencies, or linking named entities to Wikidata.",
      "description_length": 651,
      "index": 13,
      "embedding_norm": 0.9999999403953552
    }
  ],
  "filtering": {
    "total_modules_in_package": 14,
    "meaningful_modules": 14,
    "filtered_empty_modules": 0,
    "retention_rate": 1.0
  },
  "statistics": {
    "max_description_length": 651,
    "min_description_length": 275,
    "avg_description_length": 391.64285714285717,
    "embedding_file_size_mb": 0.05128288269042969
  }
}