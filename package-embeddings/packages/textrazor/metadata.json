{
  "package": "textrazor",
  "embedding_model": "Qwen/Qwen3-Embedding-8B",
  "embedding_dimension": 4096,
  "total_modules": 14,
  "creation_timestamp": "2025-08-14T23:18:42.633394",
  "modules": [
    {
      "module_path": "Textrazor.Analysis.Options",
      "library": "textrazor",
      "description": "This module defines configuration options for text analysis, including classifiers, extractors, and cleanup modes. It works with strings, lists, and records to specify analysis parameters like language, entity types, and output formatting. Concrete use cases include setting up API requests to extract entities, classify content under IAB or IPTC taxonomies, and control text sanitization behavior.",
      "description_length": 398,
      "index": 0,
      "embedding_norm": 1.0
    },
    {
      "module_path": "Textrazor.Phrase",
      "library": "textrazor",
      "description": "This module represents phrases identified in text analysis, with each phrase having an unique identifier and a list of positions indicating its occurrence. It provides functionality to construct phrase instances from JSON data using `of_yojson`. Concrete use cases include extracting and tracking specific phrases in natural language processing tasks such as keyword detection or text summarization.",
      "description_length": 399,
      "index": 1,
      "embedding_norm": 1.0
    },
    {
      "module_path": "Textrazor.Analysis",
      "library": "textrazor",
      "description": "This module analyzes text using the TextRazor API, providing structured output with entities, topics, relations, and other linguistic features. It works with text inputs and configuration options to extract semantic metadata, supporting use cases like content classification, entity recognition, and text summarization. Key functions include submitting analysis requests and parsing detailed results into typed data structures.",
      "description_length": 427,
      "index": 2,
      "embedding_norm": 0.9999999403953552
    },
    {
      "module_path": "Textrazor.Property",
      "library": "textrazor",
      "description": "This module defines a data structure representing a property with identifiers and positional data, including the property's ID, word positions, and property positions. It provides a function to safely parse this structure from a Yojson representation, handling potential parsing errors. This module is used to extract and organize structured property data from text analysis results, particularly in NLP tasks involving entity and property detection.",
      "description_length": 450,
      "index": 3,
      "embedding_norm": 1.0
    },
    {
      "module_path": "Textrazor.Account",
      "library": "textrazor",
      "description": "This module provides a function to retrieve account information from the API, returning details about request limits and usage. It works with a record type that includes integers and strings to represent account metrics like daily request limits and current usage. A concrete use case is checking the remaining API quota to avoid exceeding rate limits during text analysis operations.",
      "description_length": 384,
      "index": 4,
      "embedding_norm": 1.0
    },
    {
      "module_path": "Textrazor.Client",
      "library": "textrazor",
      "description": "This module handles HTTP communication with the Textrazor API, providing functions to create a client configuration and send GET or POST requests. It works with strings for API paths, client configuration records containing authentication and endpoint settings, and returns responses as either JSON data or error messages. Concrete use cases include sending text analysis requests to the API and retrieving structured results for natural language processing tasks.",
      "description_length": 464,
      "index": 5,
      "embedding_norm": 0.9999999403953552
    },
    {
      "module_path": "Textrazor.Relation",
      "library": "textrazor",
      "description": "This module defines data structures and JSON parsing functions for representing linguistic relations in text analysis. It works with types that include relation identifiers, parameter lists containing relation types and word positions, and word position indices. It is used to extract and process syntactic relationships between words in a sentence, such as subject-object or verb-modifier dependencies, from JSON data returned by the Textrazor API.",
      "description_length": 449,
      "index": 6,
      "embedding_norm": 1.0
    },
    {
      "module_path": "Textrazor.Topic",
      "library": "textrazor",
      "description": "This module defines a data structure representing topics extracted from text, with identifiers, labels, confidence scores, and optional links to Wikidata and Wikipedia. It provides functions to parse topic data from JSON and construct URIs for external references. Concrete use cases include enriching text analysis with linked data or integrating topic results into applications requiring semantic context.",
      "description_length": 407,
      "index": 7,
      "embedding_norm": 1.0
    },
    {
      "module_path": "Textrazor.Word",
      "library": "textrazor",
      "description": "This module defines a record type representing a word with linguistic attributes such as position, part of speech, and lemma. It includes a function to construct a word from JSON data. It is used to process and analyze individual words extracted from text, particularly for natural language processing tasks like tokenization and syntactic analysis.",
      "description_length": 349,
      "index": 8,
      "embedding_norm": 1.0
    },
    {
      "module_path": "Textrazor.Entailment",
      "library": "textrazor",
      "description": "This module defines a type `t` representing entailment results with scores, word lists, and positions. It includes a function `of_yojson` to parse these results from JSON. Use this module to extract and process entailment data from TextRazor's API responses, such as identifying entailed terms and their relevance scores in text analysis tasks.",
      "description_length": 344,
      "index": 9,
      "embedding_norm": 0.9999999403953552
    },
    {
      "module_path": "Textrazor.Sentence",
      "library": "textrazor",
      "description": "Represents a sentence in a text analysis context, containing its position and constituent words. Provides functionality to parse sentence data from JSON into a structured format with typed fields. Useful for extracting and processing individual sentences from larger textual datasets.",
      "description_length": 284,
      "index": 10,
      "embedding_norm": 1.0
    },
    {
      "module_path": "Textrazor.Entity",
      "library": "textrazor",
      "description": "This module defines a structured representation of entities extracted from text, including metadata like position, type, and external identifiers. It provides functions to parse entity data from JSON and construct URIs for Wikidata, Freebase, and Wikipedia links. Use this module to analyze and link entities to knowledge bases based on their semantic context and identifiers.",
      "description_length": 376,
      "index": 11,
      "embedding_norm": 1.0
    },
    {
      "module_path": "Textrazor.Category",
      "library": "textrazor",
      "description": "This module defines a category type with fields for classifier ID, category ID, label, and score, and provides a function to parse this structure from a Yojson value. It is used to represent and process categorized data from the Textrazor API, such as classifying text into topics or domains. A concrete use case is extracting semantic categories from text responses in a machine learning or NLP pipeline.",
      "description_length": 405,
      "index": 12,
      "embedding_norm": 0.9999999403953552
    },
    {
      "module_path": "Textrazor",
      "library": "textrazor",
      "description": "This module integrates with the TextRazor API to perform semantic text analysis, providing structured data extraction such as entities, topics, relations, and entailments. It works with text inputs and API responses, converting them into typed data structures like records and lists for precise analysis. Concrete use cases include semantic content classification, entity linking to knowledge bases, syntactic dependency extraction, and tracking phrase occurrences in natural language processing pipelines.",
      "description_length": 506,
      "index": 13,
      "embedding_norm": 1.0
    }
  ],
  "filtering": {
    "total_modules_in_package": 14,
    "meaningful_modules": 14,
    "filtered_empty_modules": 0,
    "retention_rate": 1.0
  },
  "statistics": {
    "max_description_length": 506,
    "min_description_length": 284,
    "avg_description_length": 403.0,
    "embedding_file_size_mb": 0.20336627960205078
  }
}