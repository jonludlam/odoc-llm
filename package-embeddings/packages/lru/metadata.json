{
  "package": "lru",
  "embedding_model": "Qwen/Qwen3-Embedding-0.6B",
  "embedding_dimension": 1024,
  "total_modules": 9,
  "creation_timestamp": "2025-07-15T23:07:20.046771",
  "modules": [
    {
      "module_path": "Lru.F.S",
      "library": "lru",
      "description": "The module provides a functional LRU cache implementation using a priority search queue to manage key-value bindings under weight-based capacity constraints. It supports operations like insertion, removal, promotion, and weight-aware trimming with logarithmic time complexity, along with folding, iteration, and bulk conversions sensitive to usage order or key sorting. This structure is ideal for resource caching scenarios where items have variable weights, such as memory or network resource management, ensuring efficient eviction of least-recently-used entries while preserving immutability.",
      "description_length": 596,
      "index": 0,
      "embedding_norm": 1.0
    },
    {
      "module_path": "Lru.M.MakeSeeded",
      "library": "lru",
      "description": "This module implements a mutable LRU cache with weight-based capacity control, offering operations to insert, remove, and access key-value pairs while maintaining least-recently-used eviction semantics. It combines a hash table with a doubly-linked list to track usage order and supports traversal, serialization, and human-readable output for debugging. Suitable for resource-constrained caching scenarios where entries have variable weights, such as memory-limited object pools or prioritized data buffering.",
      "description_length": 510,
      "index": 1,
      "embedding_norm": 0.9999999403953552
    },
    {
      "module_path": "Lru.M.Make",
      "library": "lru",
      "description": "This module implements a mutable cache with weighted capacity management, using a hash table paired with a doubly-linked list to enable O(1) access and LRU-based eviction. It supports key-value operations, iteration in LRU-to-MRU order, and automatic trimming when cumulative weights exceed capacity, making it suitable for resource-constrained caching scenarios like memory-sensitive data retention or bounded-size lookup tables. The module works with arbitrary key and value types where weights are derived from values, enabling use cases that require prioritizing recently used entries while respecting dynamic size limits.",
      "description_length": 626,
      "index": 2,
      "embedding_norm": 1.0
    },
    {
      "module_path": "Lru.M.S",
      "library": "lru",
      "description": "This module implements a mutable finite map with weight-bounded capacity, using a hash table and doubly-linked list to track key-value pairs. It supports operations for inserting, accessing, and removing elements with customizable weights, automatically evicting least-recently-used entries when the cumulative weight exceeds a configured limit. Such structures are useful for memory-constrained caching scenarios where entries vary in size or resource footprint, requiring efficient O(1) access patterns while maintaining strict capacity bounds.",
      "description_length": 546,
      "index": 3,
      "embedding_norm": 1.0
    },
    {
      "module_path": "Lru.F.Make",
      "library": "lru",
      "description": "This module implements a weight-bounded functional cache with operations to insert, remove, and retrieve key-value pairs while enforcing capacity limits through LRU eviction. It uses an ordered map structure where keys are compared via `K.t` and values carry weights determined by `V.t`, maintaining internal consistency through priority search queues. Typical applications include memory-constrained caches where entries require variable weighting (e.g., byte-size tracking) or bounded session stores where temporal access patterns dictate retention priority.",
      "description_length": 560,
      "index": 4,
      "embedding_norm": 1.0
    },
    {
      "module_path": "Lru.M",
      "library": "lru",
      "description": "This module provides a mutable LRU map backed by a hash table and doubly-linked list, supporting O(1) insertion, lookup, and removal while maintaining a total weight limit. It automatically evicts least-recently-used entries when capacity is exceeded, making it suitable for memory-constrained caching such as HTTP response buffers or session stores. The module supports key-value operations, iteration in LRU-to-MRU order, and customizable weight functions, enabling efficient resource management for variable-sized entries. Submodules extend this functionality with traversal, serialization, and debugging capabilities, all while preserving the core eviction and access semantics.",
      "description_length": 682,
      "index": 5,
      "embedding_norm": 0.9999999403953552
    },
    {
      "module_path": "Lru.Weighted",
      "library": "lru",
      "description": "This module defines types with a measurable weight, used to determine their contribution to a capacity-limited LRU cache. It includes a function `weight` that returns a strictly positive integer representing the weight of a value. This interface is essential for managing cache entries where each binding's impact on the total capacity must be explicitly defined.",
      "description_length": 363,
      "index": 6,
      "embedding_norm": 1.0
    },
    {
      "module_path": "Lru.F",
      "library": "lru",
      "description": "This module implements a functional LRU map using a priority search queue to manage weighted key-value pairs, automatically evicting least-recently-used entries to stay within a specified weight limit. It supports efficient insertion, lookup, deletion, and promotion operations in logarithmic time, with concrete use cases including caches for HTTP responses or bounded in-memory stores with prioritized entries. The child modules refine this structure with weight-aware trimming, ordered key comparisons, and usage-sensitive iteration, enabling applications like size-constrained memory caches or session stores with temporal access patterns. Together, they provide a coherent API for managing immutable, capacity-limited collections where both key ordering and access frequency influence retention.",
      "description_length": 800,
      "index": 7,
      "embedding_norm": 1.0
    },
    {
      "module_path": "Lru",
      "library": "lru",
      "description": "This module implements weight-bounded LRU caches that automatically evict least-recently-used entries to stay within a capacity limit, supporting both functional and imperative map variants. The mutable map uses a hash table and doubly-linked list for O(1) operations, while the functional map uses a priority search queue with O(log n) performance, both tracking access order and entry weights to manage memory-constrained storage. It handles key-value pairs where each value has a defined weight, enabling use cases like caching HTTP responses, session stores, or bounded in-memory databases. Submodules provide weight definitions, ordered traversal, and trimming logic, extending core operations with customizable weight functions, access-pattern-sensitive iteration, and efficient size management.",
      "description_length": 801,
      "index": 8,
      "embedding_norm": 0.9999999403953552
    }
  ],
  "filtering": {
    "total_modules_in_package": 9,
    "meaningful_modules": 9,
    "filtered_empty_modules": 0,
    "retention_rate": 1.0
  },
  "statistics": {
    "max_description_length": 801,
    "min_description_length": 363,
    "avg_description_length": 609.3333333333334,
    "embedding_file_size_mb": 0.033110618591308594
  }
}